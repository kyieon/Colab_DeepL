{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dacon7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOJmALsXNrFj2ZOwFlIR48r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyieon/Colab_DeepL/blob/master/Dacon7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7RJGOIlKPon",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "b9c4a6b8-fcf7-4766-de66-a47787c7b81b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToZJ5y-KRLC7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "d7a5540e-ff61-413a-fd5e-17a2d1f92ad2"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/Dacon7')\n",
        "!unzip data.zip\n",
        "!ls"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "replace submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: all\n",
            "error:  invalid response [all]\n",
            "replace submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: submission.csv          \n",
            "replace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: test.csv                \n",
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: train.csv               \n",
            "Dacon7.ipynb  data.zip\tresult.csv  submission.csv  test.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv3zOKrqzs1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, Dropout, Activation\n",
        "from keras.optimizers import RMSprop, Nadam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luXBD5mk0n74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 실제 이미지 보기\n",
        "# test_df = pd.read_csv('test.csv', index_col=0)\n",
        "\n",
        "# for i in range(5):  \n",
        "#   img = np.array(test_df.iloc[i, 1:]).reshape(28, 28).astype(np.float)\n",
        "#   plt.imshow(img)\n",
        "#   plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAY2Wzw6P82Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.01, # Randomly zoom image \n",
        "        width_shift_range=0.01,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.01,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False\n",
        "        )"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k59fV07PTZFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6bc174f0-7b0d-4ebd-8607-129ce3dc3fd9"
      },
      "source": [
        "# 트레이닝\n",
        "\n",
        "train_df = pd.read_csv('train.csv', index_col=0)\n",
        "\n",
        "x_train = np.array(train_df.iloc[:, 2:]).reshape(-1, 28, 28, 1).astype(np.float)\n",
        "y_train = to_categorical(train_df['digit'].values.astype('int32'), 10)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, train_size=0.8)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(64, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(128, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(256, kernel_size=(3,3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=Nadam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "EPOCHS = 1000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "hits = model.fit(\n",
        "    x_train, y_train, batch_size=BATCH_SIZE, \n",
        "    epochs=EPOCHS, \n",
        "    validation_data=(x_test, y_test),\n",
        "     verbose=1\n",
        "    )\n",
        "\n",
        "\n",
        "# hits = model.fit(\n",
        "#     datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
        "#     epochs=EPOCHS,\n",
        "#     validation_data=(x_test, y_test),\n",
        "#     verbose=1\n",
        "# )\n",
        "\n",
        "# print(\n",
        "#     f\"resNET CNN : Epochs={EPOCHS:d}, \" +\n",
        "#     f\"Train accuracy={max(hits.history['accuracy']):.4f}, \" +\n",
        "#     f\"Validation accuracy={max(hits.history['val_accuracy']):.4f}\"\n",
        "# )\n",
        "\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_53\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_214 (Conv2D)          (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_206 (MaxPoolin (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_253 (Dropout)        (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_215 (Conv2D)          (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_207 (MaxPoolin (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_254 (Dropout)        (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_216 (Conv2D)          (None, 7, 7, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_208 (MaxPoolin (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_255 (Dropout)        (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_217 (Conv2D)          (None, 3, 3, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_209 (MaxPoolin (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_256 (Dropout)        (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_49 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_98 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_257 (Dropout)        (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_99 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 524,554\n",
            "Trainable params: 524,554\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "26/26 [==============================] - 0s 14ms/step - loss: 8.8681 - accuracy: 0.0971 - val_loss: 2.2975 - val_accuracy: 0.1220\n",
            "Epoch 2/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.5731 - accuracy: 0.1032 - val_loss: 2.2977 - val_accuracy: 0.1098\n",
            "Epoch 3/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.4022 - accuracy: 0.1117 - val_loss: 2.2971 - val_accuracy: 0.1317\n",
            "Epoch 4/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.3844 - accuracy: 0.1038 - val_loss: 2.3007 - val_accuracy: 0.1073\n",
            "Epoch 5/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.3404 - accuracy: 0.1117 - val_loss: 2.3018 - val_accuracy: 0.0854\n",
            "Epoch 6/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.3402 - accuracy: 0.1074 - val_loss: 2.3005 - val_accuracy: 0.1220\n",
            "Epoch 7/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.3342 - accuracy: 0.1044 - val_loss: 2.2997 - val_accuracy: 0.1293\n",
            "Epoch 8/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.3186 - accuracy: 0.1142 - val_loss: 2.3007 - val_accuracy: 0.1146\n",
            "Epoch 9/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.3130 - accuracy: 0.1068 - val_loss: 2.3017 - val_accuracy: 0.1073\n",
            "Epoch 10/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.3252 - accuracy: 0.0885 - val_loss: 2.3012 - val_accuracy: 0.1073\n",
            "Epoch 11/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.3094 - accuracy: 0.1056 - val_loss: 2.3008 - val_accuracy: 0.1171\n",
            "Epoch 12/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.2977 - accuracy: 0.1239 - val_loss: 2.2981 - val_accuracy: 0.1268\n",
            "Epoch 13/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.3001 - accuracy: 0.1056 - val_loss: 2.2988 - val_accuracy: 0.1171\n",
            "Epoch 14/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.2977 - accuracy: 0.1203 - val_loss: 2.2948 - val_accuracy: 0.1268\n",
            "Epoch 15/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.3058 - accuracy: 0.1136 - val_loss: 2.2936 - val_accuracy: 0.1293\n",
            "Epoch 16/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.2917 - accuracy: 0.1282 - val_loss: 2.2884 - val_accuracy: 0.1341\n",
            "Epoch 17/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.2844 - accuracy: 0.1337 - val_loss: 2.2898 - val_accuracy: 0.1122\n",
            "Epoch 18/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.2830 - accuracy: 0.1270 - val_loss: 2.2857 - val_accuracy: 0.1341\n",
            "Epoch 19/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.2858 - accuracy: 0.1215 - val_loss: 2.2884 - val_accuracy: 0.1268\n",
            "Epoch 20/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.2742 - accuracy: 0.1422 - val_loss: 2.2793 - val_accuracy: 0.1439\n",
            "Epoch 21/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.2746 - accuracy: 0.1343 - val_loss: 2.2711 - val_accuracy: 0.1854\n",
            "Epoch 22/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.2621 - accuracy: 0.1441 - val_loss: 2.2733 - val_accuracy: 0.1488\n",
            "Epoch 23/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.2567 - accuracy: 0.1545 - val_loss: 2.2494 - val_accuracy: 0.1829\n",
            "Epoch 24/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.2501 - accuracy: 0.1581 - val_loss: 2.2483 - val_accuracy: 0.1805\n",
            "Epoch 25/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.2378 - accuracy: 0.1575 - val_loss: 2.2563 - val_accuracy: 0.1780\n",
            "Epoch 26/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.2531 - accuracy: 0.1490 - val_loss: 2.2410 - val_accuracy: 0.1902\n",
            "Epoch 27/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.2284 - accuracy: 0.1630 - val_loss: 2.2199 - val_accuracy: 0.2341\n",
            "Epoch 28/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.2264 - accuracy: 0.1709 - val_loss: 2.2254 - val_accuracy: 0.2171\n",
            "Epoch 29/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.2077 - accuracy: 0.1838 - val_loss: 2.1921 - val_accuracy: 0.2463\n",
            "Epoch 30/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.2009 - accuracy: 0.1740 - val_loss: 2.1760 - val_accuracy: 0.2439\n",
            "Epoch 31/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.1936 - accuracy: 0.1783 - val_loss: 2.1659 - val_accuracy: 0.2878\n",
            "Epoch 32/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.1389 - accuracy: 0.1911 - val_loss: 2.1358 - val_accuracy: 0.2976\n",
            "Epoch 33/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.1498 - accuracy: 0.2198 - val_loss: 2.1372 - val_accuracy: 0.2854\n",
            "Epoch 34/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.1096 - accuracy: 0.2424 - val_loss: 2.0957 - val_accuracy: 0.2951\n",
            "Epoch 35/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.1193 - accuracy: 0.2210 - val_loss: 2.0663 - val_accuracy: 0.2976\n",
            "Epoch 36/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.0670 - accuracy: 0.2582 - val_loss: 2.0612 - val_accuracy: 0.3195\n",
            "Epoch 37/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.0807 - accuracy: 0.2473 - val_loss: 2.0659 - val_accuracy: 0.3098\n",
            "Epoch 38/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 2.0438 - accuracy: 0.2613 - val_loss: 2.0213 - val_accuracy: 0.3293\n",
            "Epoch 39/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 2.0008 - accuracy: 0.2705 - val_loss: 1.9973 - val_accuracy: 0.3756\n",
            "Epoch 40/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.9843 - accuracy: 0.2735 - val_loss: 1.9826 - val_accuracy: 0.3341\n",
            "Epoch 41/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.9752 - accuracy: 0.2955 - val_loss: 1.9500 - val_accuracy: 0.3561\n",
            "Epoch 42/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.9506 - accuracy: 0.2912 - val_loss: 1.9024 - val_accuracy: 0.4171\n",
            "Epoch 43/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.9003 - accuracy: 0.3205 - val_loss: 1.8744 - val_accuracy: 0.4098\n",
            "Epoch 44/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.8862 - accuracy: 0.3431 - val_loss: 1.8974 - val_accuracy: 0.3951\n",
            "Epoch 45/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.8703 - accuracy: 0.3278 - val_loss: 1.8569 - val_accuracy: 0.4073\n",
            "Epoch 46/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.8562 - accuracy: 0.3382 - val_loss: 1.8404 - val_accuracy: 0.4244\n",
            "Epoch 47/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.8607 - accuracy: 0.3437 - val_loss: 1.8481 - val_accuracy: 0.4244\n",
            "Epoch 48/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.8193 - accuracy: 0.3565 - val_loss: 1.8200 - val_accuracy: 0.4122\n",
            "Epoch 49/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.8192 - accuracy: 0.3681 - val_loss: 1.7854 - val_accuracy: 0.4439\n",
            "Epoch 50/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.7729 - accuracy: 0.3816 - val_loss: 1.7780 - val_accuracy: 0.4341\n",
            "Epoch 51/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.7630 - accuracy: 0.3828 - val_loss: 1.7680 - val_accuracy: 0.4512\n",
            "Epoch 52/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.7531 - accuracy: 0.3736 - val_loss: 1.7351 - val_accuracy: 0.4610\n",
            "Epoch 53/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.7205 - accuracy: 0.4042 - val_loss: 1.7461 - val_accuracy: 0.4659\n",
            "Epoch 54/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.7072 - accuracy: 0.4090 - val_loss: 1.6991 - val_accuracy: 0.4927\n",
            "Epoch 55/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.6836 - accuracy: 0.4206 - val_loss: 1.7771 - val_accuracy: 0.4171\n",
            "Epoch 56/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.6616 - accuracy: 0.4231 - val_loss: 1.7101 - val_accuracy: 0.4610\n",
            "Epoch 57/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.6648 - accuracy: 0.4029 - val_loss: 1.7122 - val_accuracy: 0.4561\n",
            "Epoch 58/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.6207 - accuracy: 0.4383 - val_loss: 1.6320 - val_accuracy: 0.5537\n",
            "Epoch 59/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.6346 - accuracy: 0.4328 - val_loss: 1.6258 - val_accuracy: 0.5122\n",
            "Epoch 60/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.6158 - accuracy: 0.4475 - val_loss: 1.6636 - val_accuracy: 0.4707\n",
            "Epoch 61/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.5565 - accuracy: 0.4512 - val_loss: 1.5233 - val_accuracy: 0.5317\n",
            "Epoch 62/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.5680 - accuracy: 0.4695 - val_loss: 1.5511 - val_accuracy: 0.5488\n",
            "Epoch 63/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.5381 - accuracy: 0.4750 - val_loss: 1.5301 - val_accuracy: 0.5463\n",
            "Epoch 64/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.5120 - accuracy: 0.4951 - val_loss: 1.4777 - val_accuracy: 0.5463\n",
            "Epoch 65/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.5197 - accuracy: 0.4628 - val_loss: 1.4658 - val_accuracy: 0.5561\n",
            "Epoch 66/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.4432 - accuracy: 0.5098 - val_loss: 1.4378 - val_accuracy: 0.5439\n",
            "Epoch 67/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.4671 - accuracy: 0.4982 - val_loss: 1.6164 - val_accuracy: 0.4707\n",
            "Epoch 68/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.4791 - accuracy: 0.4933 - val_loss: 1.4601 - val_accuracy: 0.5610\n",
            "Epoch 69/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.4202 - accuracy: 0.5189 - val_loss: 1.4837 - val_accuracy: 0.5659\n",
            "Epoch 70/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.4224 - accuracy: 0.5220 - val_loss: 1.5314 - val_accuracy: 0.5244\n",
            "Epoch 71/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.4205 - accuracy: 0.5061 - val_loss: 1.4768 - val_accuracy: 0.5439\n",
            "Epoch 72/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.4323 - accuracy: 0.5183 - val_loss: 1.4322 - val_accuracy: 0.5805\n",
            "Epoch 73/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.3503 - accuracy: 0.5433 - val_loss: 1.4339 - val_accuracy: 0.5537\n",
            "Epoch 74/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.3861 - accuracy: 0.5281 - val_loss: 1.3472 - val_accuracy: 0.6073\n",
            "Epoch 75/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.3759 - accuracy: 0.5305 - val_loss: 1.3528 - val_accuracy: 0.5878\n",
            "Epoch 76/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2910 - accuracy: 0.5611 - val_loss: 1.3155 - val_accuracy: 0.6146\n",
            "Epoch 77/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2983 - accuracy: 0.5488 - val_loss: 1.3329 - val_accuracy: 0.5951\n",
            "Epoch 78/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.2791 - accuracy: 0.5739 - val_loss: 1.3052 - val_accuracy: 0.5878\n",
            "Epoch 79/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2696 - accuracy: 0.5702 - val_loss: 1.3697 - val_accuracy: 0.5829\n",
            "Epoch 80/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2819 - accuracy: 0.5647 - val_loss: 1.3940 - val_accuracy: 0.5610\n",
            "Epoch 81/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2535 - accuracy: 0.5629 - val_loss: 1.3927 - val_accuracy: 0.5829\n",
            "Epoch 82/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.2367 - accuracy: 0.5873 - val_loss: 1.3643 - val_accuracy: 0.5780\n",
            "Epoch 83/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.1569 - accuracy: 0.6050 - val_loss: 1.3110 - val_accuracy: 0.5902\n",
            "Epoch 84/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2275 - accuracy: 0.5824 - val_loss: 1.2968 - val_accuracy: 0.6171\n",
            "Epoch 85/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.1351 - accuracy: 0.6081 - val_loss: 1.2684 - val_accuracy: 0.5951\n",
            "Epoch 86/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.1665 - accuracy: 0.5934 - val_loss: 1.2587 - val_accuracy: 0.5976\n",
            "Epoch 87/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 1.1752 - accuracy: 0.6020 - val_loss: 1.3653 - val_accuracy: 0.5805\n",
            "Epoch 88/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.2076 - accuracy: 0.5952 - val_loss: 1.2959 - val_accuracy: 0.5976\n",
            "Epoch 89/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0929 - accuracy: 0.6252 - val_loss: 1.1821 - val_accuracy: 0.6659\n",
            "Epoch 90/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.1430 - accuracy: 0.6099 - val_loss: 1.1757 - val_accuracy: 0.6585\n",
            "Epoch 91/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.1089 - accuracy: 0.6361 - val_loss: 1.1977 - val_accuracy: 0.6317\n",
            "Epoch 92/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.1082 - accuracy: 0.6038 - val_loss: 1.1927 - val_accuracy: 0.6366\n",
            "Epoch 93/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0573 - accuracy: 0.6471 - val_loss: 1.1147 - val_accuracy: 0.6512\n",
            "Epoch 94/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0698 - accuracy: 0.6392 - val_loss: 1.1467 - val_accuracy: 0.6293\n",
            "Epoch 95/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0764 - accuracy: 0.6441 - val_loss: 1.2652 - val_accuracy: 0.6341\n",
            "Epoch 96/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0463 - accuracy: 0.6612 - val_loss: 1.2504 - val_accuracy: 0.6122\n",
            "Epoch 97/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0719 - accuracy: 0.6392 - val_loss: 1.2325 - val_accuracy: 0.6415\n",
            "Epoch 98/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0471 - accuracy: 0.6453 - val_loss: 1.1550 - val_accuracy: 0.6683\n",
            "Epoch 99/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9834 - accuracy: 0.6630 - val_loss: 1.0808 - val_accuracy: 0.6805\n",
            "Epoch 100/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0315 - accuracy: 0.6545 - val_loss: 1.1983 - val_accuracy: 0.6146\n",
            "Epoch 101/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 1.0108 - accuracy: 0.6679 - val_loss: 1.2896 - val_accuracy: 0.6122\n",
            "Epoch 102/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9890 - accuracy: 0.6813 - val_loss: 1.0422 - val_accuracy: 0.6951\n",
            "Epoch 103/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9811 - accuracy: 0.6722 - val_loss: 1.1996 - val_accuracy: 0.6415\n",
            "Epoch 104/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.9396 - accuracy: 0.6783 - val_loss: 1.2242 - val_accuracy: 0.6268\n",
            "Epoch 105/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9228 - accuracy: 0.6899 - val_loss: 1.1327 - val_accuracy: 0.6463\n",
            "Epoch 106/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.9561 - accuracy: 0.6844 - val_loss: 1.2846 - val_accuracy: 0.6049\n",
            "Epoch 107/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9468 - accuracy: 0.6850 - val_loss: 1.1625 - val_accuracy: 0.6439\n",
            "Epoch 108/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9721 - accuracy: 0.6734 - val_loss: 1.1454 - val_accuracy: 0.6585\n",
            "Epoch 109/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.8993 - accuracy: 0.6966 - val_loss: 1.1399 - val_accuracy: 0.6634\n",
            "Epoch 110/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9310 - accuracy: 0.6856 - val_loss: 1.1023 - val_accuracy: 0.6561\n",
            "Epoch 111/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.9267 - accuracy: 0.7051 - val_loss: 1.1813 - val_accuracy: 0.6341\n",
            "Epoch 112/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.8795 - accuracy: 0.7076 - val_loss: 1.0987 - val_accuracy: 0.6805\n",
            "Epoch 113/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.8878 - accuracy: 0.6935 - val_loss: 1.0520 - val_accuracy: 0.6585\n",
            "Epoch 114/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.8548 - accuracy: 0.7234 - val_loss: 1.0391 - val_accuracy: 0.6878\n",
            "Epoch 115/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.8582 - accuracy: 0.7045 - val_loss: 1.2005 - val_accuracy: 0.6073\n",
            "Epoch 116/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.8312 - accuracy: 0.7192 - val_loss: 1.1794 - val_accuracy: 0.6415\n",
            "Epoch 117/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.8467 - accuracy: 0.7149 - val_loss: 0.9453 - val_accuracy: 0.6878\n",
            "Epoch 118/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.8379 - accuracy: 0.7326 - val_loss: 1.0683 - val_accuracy: 0.6512\n",
            "Epoch 119/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.8172 - accuracy: 0.7302 - val_loss: 1.0741 - val_accuracy: 0.6683\n",
            "Epoch 120/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.8057 - accuracy: 0.7338 - val_loss: 1.1909 - val_accuracy: 0.6000\n",
            "Epoch 121/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.7803 - accuracy: 0.7491 - val_loss: 1.1153 - val_accuracy: 0.6317\n",
            "Epoch 122/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.7944 - accuracy: 0.7302 - val_loss: 0.9939 - val_accuracy: 0.6829\n",
            "Epoch 123/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.7794 - accuracy: 0.7289 - val_loss: 1.0031 - val_accuracy: 0.6854\n",
            "Epoch 124/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.7950 - accuracy: 0.7350 - val_loss: 1.0184 - val_accuracy: 0.6683\n",
            "Epoch 125/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.7797 - accuracy: 0.7387 - val_loss: 1.0171 - val_accuracy: 0.6732\n",
            "Epoch 126/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.7542 - accuracy: 0.7521 - val_loss: 1.0194 - val_accuracy: 0.6878\n",
            "Epoch 127/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.7768 - accuracy: 0.7387 - val_loss: 1.0797 - val_accuracy: 0.6439\n",
            "Epoch 128/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.7621 - accuracy: 0.7460 - val_loss: 0.9479 - val_accuracy: 0.7244\n",
            "Epoch 129/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.7680 - accuracy: 0.7540 - val_loss: 0.9988 - val_accuracy: 0.7073\n",
            "Epoch 130/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.7109 - accuracy: 0.7601 - val_loss: 0.9977 - val_accuracy: 0.7000\n",
            "Epoch 131/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.7112 - accuracy: 0.7589 - val_loss: 0.9213 - val_accuracy: 0.7195\n",
            "Epoch 132/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.7027 - accuracy: 0.7723 - val_loss: 0.9928 - val_accuracy: 0.7073\n",
            "Epoch 133/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.7188 - accuracy: 0.7650 - val_loss: 0.9864 - val_accuracy: 0.6878\n",
            "Epoch 134/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.7142 - accuracy: 0.7711 - val_loss: 1.0092 - val_accuracy: 0.7000\n",
            "Epoch 135/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.7330 - accuracy: 0.7582 - val_loss: 0.8925 - val_accuracy: 0.7171\n",
            "Epoch 136/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.6815 - accuracy: 0.7631 - val_loss: 1.0005 - val_accuracy: 0.6902\n",
            "Epoch 137/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.6998 - accuracy: 0.7674 - val_loss: 0.9262 - val_accuracy: 0.7195\n",
            "Epoch 138/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.6782 - accuracy: 0.7772 - val_loss: 0.8962 - val_accuracy: 0.7171\n",
            "Epoch 139/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.7031 - accuracy: 0.7656 - val_loss: 0.9496 - val_accuracy: 0.7171\n",
            "Epoch 140/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.6342 - accuracy: 0.7888 - val_loss: 0.8701 - val_accuracy: 0.7366\n",
            "Epoch 141/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.6369 - accuracy: 0.7918 - val_loss: 0.9963 - val_accuracy: 0.6927\n",
            "Epoch 142/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.6804 - accuracy: 0.7735 - val_loss: 1.0883 - val_accuracy: 0.6561\n",
            "Epoch 143/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.6728 - accuracy: 0.7814 - val_loss: 1.0850 - val_accuracy: 0.6512\n",
            "Epoch 144/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.6292 - accuracy: 0.7900 - val_loss: 0.9727 - val_accuracy: 0.7146\n",
            "Epoch 145/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.6199 - accuracy: 0.7973 - val_loss: 1.0449 - val_accuracy: 0.6878\n",
            "Epoch 146/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.6185 - accuracy: 0.7967 - val_loss: 1.0701 - val_accuracy: 0.6902\n",
            "Epoch 147/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.6413 - accuracy: 0.7857 - val_loss: 0.8192 - val_accuracy: 0.7390\n",
            "Epoch 148/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5907 - accuracy: 0.7961 - val_loss: 0.9963 - val_accuracy: 0.7024\n",
            "Epoch 149/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.6548 - accuracy: 0.7784 - val_loss: 0.8993 - val_accuracy: 0.7341\n",
            "Epoch 150/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.5844 - accuracy: 0.7961 - val_loss: 0.9452 - val_accuracy: 0.7049\n",
            "Epoch 151/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.6494 - accuracy: 0.7814 - val_loss: 0.9555 - val_accuracy: 0.6976\n",
            "Epoch 152/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.6292 - accuracy: 0.7930 - val_loss: 0.8270 - val_accuracy: 0.7488\n",
            "Epoch 153/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5770 - accuracy: 0.8065 - val_loss: 1.0499 - val_accuracy: 0.6659\n",
            "Epoch 154/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.5903 - accuracy: 0.8083 - val_loss: 0.8158 - val_accuracy: 0.7268\n",
            "Epoch 155/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5862 - accuracy: 0.8138 - val_loss: 1.0072 - val_accuracy: 0.7098\n",
            "Epoch 156/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.6163 - accuracy: 0.7900 - val_loss: 0.9145 - val_accuracy: 0.7146\n",
            "Epoch 157/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5791 - accuracy: 0.8107 - val_loss: 1.1343 - val_accuracy: 0.6415\n",
            "Epoch 158/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.6003 - accuracy: 0.7930 - val_loss: 0.8466 - val_accuracy: 0.7341\n",
            "Epoch 159/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.5708 - accuracy: 0.8077 - val_loss: 0.8744 - val_accuracy: 0.7171\n",
            "Epoch 160/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5836 - accuracy: 0.8053 - val_loss: 0.9609 - val_accuracy: 0.6951\n",
            "Epoch 161/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5386 - accuracy: 0.8260 - val_loss: 0.9321 - val_accuracy: 0.7073\n",
            "Epoch 162/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5328 - accuracy: 0.8223 - val_loss: 0.7638 - val_accuracy: 0.7512\n",
            "Epoch 163/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.5758 - accuracy: 0.8126 - val_loss: 0.8748 - val_accuracy: 0.7366\n",
            "Epoch 164/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5598 - accuracy: 0.8193 - val_loss: 0.8401 - val_accuracy: 0.7488\n",
            "Epoch 165/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.5337 - accuracy: 0.8242 - val_loss: 0.9818 - val_accuracy: 0.6829\n",
            "Epoch 166/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5092 - accuracy: 0.8333 - val_loss: 0.8934 - val_accuracy: 0.7293\n",
            "Epoch 167/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5409 - accuracy: 0.8223 - val_loss: 0.8226 - val_accuracy: 0.7390\n",
            "Epoch 168/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4984 - accuracy: 0.8291 - val_loss: 0.9526 - val_accuracy: 0.6976\n",
            "Epoch 169/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5507 - accuracy: 0.8230 - val_loss: 0.9222 - val_accuracy: 0.7098\n",
            "Epoch 170/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5083 - accuracy: 0.8303 - val_loss: 1.0673 - val_accuracy: 0.6610\n",
            "Epoch 171/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4637 - accuracy: 0.8437 - val_loss: 0.7744 - val_accuracy: 0.7512\n",
            "Epoch 172/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.5466 - accuracy: 0.8187 - val_loss: 1.0941 - val_accuracy: 0.6537\n",
            "Epoch 173/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4928 - accuracy: 0.8278 - val_loss: 0.9187 - val_accuracy: 0.7024\n",
            "Epoch 174/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5009 - accuracy: 0.8260 - val_loss: 0.9886 - val_accuracy: 0.6878\n",
            "Epoch 175/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5222 - accuracy: 0.8339 - val_loss: 0.8572 - val_accuracy: 0.7341\n",
            "Epoch 176/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5376 - accuracy: 0.8211 - val_loss: 0.8132 - val_accuracy: 0.7415\n",
            "Epoch 177/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.5057 - accuracy: 0.8352 - val_loss: 0.8891 - val_accuracy: 0.7146\n",
            "Epoch 178/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4823 - accuracy: 0.8382 - val_loss: 0.8124 - val_accuracy: 0.7463\n",
            "Epoch 179/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4978 - accuracy: 0.8437 - val_loss: 0.8603 - val_accuracy: 0.7293\n",
            "Epoch 180/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4429 - accuracy: 0.8529 - val_loss: 0.7748 - val_accuracy: 0.7512\n",
            "Epoch 181/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4896 - accuracy: 0.8321 - val_loss: 0.8378 - val_accuracy: 0.7390\n",
            "Epoch 182/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.5144 - accuracy: 0.8339 - val_loss: 0.8972 - val_accuracy: 0.7244\n",
            "Epoch 183/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4533 - accuracy: 0.8425 - val_loss: 0.8098 - val_accuracy: 0.7512\n",
            "Epoch 184/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.4620 - accuracy: 0.8510 - val_loss: 0.8011 - val_accuracy: 0.7341\n",
            "Epoch 185/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4863 - accuracy: 0.8565 - val_loss: 0.8460 - val_accuracy: 0.7268\n",
            "Epoch 186/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.4499 - accuracy: 0.8425 - val_loss: 0.7159 - val_accuracy: 0.7732\n",
            "Epoch 187/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4863 - accuracy: 0.8339 - val_loss: 0.8562 - val_accuracy: 0.7366\n",
            "Epoch 188/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.4389 - accuracy: 0.8529 - val_loss: 0.7704 - val_accuracy: 0.7439\n",
            "Epoch 189/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.4529 - accuracy: 0.8468 - val_loss: 0.7625 - val_accuracy: 0.7488\n",
            "Epoch 190/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4802 - accuracy: 0.8486 - val_loss: 0.7395 - val_accuracy: 0.7610\n",
            "Epoch 191/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4497 - accuracy: 0.8523 - val_loss: 0.7924 - val_accuracy: 0.7561\n",
            "Epoch 192/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4509 - accuracy: 0.8510 - val_loss: 0.7758 - val_accuracy: 0.7610\n",
            "Epoch 193/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.8602 - val_loss: 0.8449 - val_accuracy: 0.7390\n",
            "Epoch 194/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4045 - accuracy: 0.8651 - val_loss: 0.9339 - val_accuracy: 0.7146\n",
            "Epoch 195/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.4569 - accuracy: 0.8529 - val_loss: 0.8254 - val_accuracy: 0.7463\n",
            "Epoch 196/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4483 - accuracy: 0.8516 - val_loss: 0.7991 - val_accuracy: 0.7366\n",
            "Epoch 197/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3863 - accuracy: 0.8645 - val_loss: 0.7965 - val_accuracy: 0.7439\n",
            "Epoch 198/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.4145 - accuracy: 0.8547 - val_loss: 0.7574 - val_accuracy: 0.7585\n",
            "Epoch 199/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4282 - accuracy: 0.8565 - val_loss: 0.7279 - val_accuracy: 0.7780\n",
            "Epoch 200/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4562 - accuracy: 0.8486 - val_loss: 1.0161 - val_accuracy: 0.6927\n",
            "Epoch 201/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3941 - accuracy: 0.8706 - val_loss: 0.8027 - val_accuracy: 0.7537\n",
            "Epoch 202/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.4073 - accuracy: 0.8639 - val_loss: 0.8122 - val_accuracy: 0.7512\n",
            "Epoch 203/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3731 - accuracy: 0.8736 - val_loss: 0.7856 - val_accuracy: 0.7537\n",
            "Epoch 204/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.4465 - accuracy: 0.8529 - val_loss: 0.8164 - val_accuracy: 0.7488\n",
            "Epoch 205/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4375 - accuracy: 0.8486 - val_loss: 0.8120 - val_accuracy: 0.7488\n",
            "Epoch 206/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3835 - accuracy: 0.8816 - val_loss: 0.7278 - val_accuracy: 0.7610\n",
            "Epoch 207/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4144 - accuracy: 0.8626 - val_loss: 0.7435 - val_accuracy: 0.7683\n",
            "Epoch 208/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4052 - accuracy: 0.8718 - val_loss: 0.8876 - val_accuracy: 0.7390\n",
            "Epoch 209/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4004 - accuracy: 0.8730 - val_loss: 0.8491 - val_accuracy: 0.7390\n",
            "Epoch 210/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3812 - accuracy: 0.8803 - val_loss: 0.8731 - val_accuracy: 0.7366\n",
            "Epoch 211/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.4032 - accuracy: 0.8645 - val_loss: 0.7949 - val_accuracy: 0.7512\n",
            "Epoch 212/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3920 - accuracy: 0.8700 - val_loss: 0.8707 - val_accuracy: 0.7220\n",
            "Epoch 213/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3749 - accuracy: 0.8730 - val_loss: 0.8027 - val_accuracy: 0.7415\n",
            "Epoch 214/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3587 - accuracy: 0.8846 - val_loss: 0.9060 - val_accuracy: 0.7073\n",
            "Epoch 215/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3885 - accuracy: 0.8700 - val_loss: 0.8245 - val_accuracy: 0.7561\n",
            "Epoch 216/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3925 - accuracy: 0.8712 - val_loss: 0.7898 - val_accuracy: 0.7585\n",
            "Epoch 217/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3631 - accuracy: 0.8822 - val_loss: 0.7653 - val_accuracy: 0.7683\n",
            "Epoch 218/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3560 - accuracy: 0.8852 - val_loss: 0.7815 - val_accuracy: 0.7634\n",
            "Epoch 219/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3534 - accuracy: 0.8816 - val_loss: 0.8277 - val_accuracy: 0.7488\n",
            "Epoch 220/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3588 - accuracy: 0.8834 - val_loss: 0.9164 - val_accuracy: 0.7390\n",
            "Epoch 221/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3914 - accuracy: 0.8718 - val_loss: 0.8369 - val_accuracy: 0.7488\n",
            "Epoch 222/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3884 - accuracy: 0.8748 - val_loss: 0.8403 - val_accuracy: 0.7585\n",
            "Epoch 223/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3626 - accuracy: 0.8907 - val_loss: 0.8066 - val_accuracy: 0.7585\n",
            "Epoch 224/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3823 - accuracy: 0.8730 - val_loss: 0.8394 - val_accuracy: 0.7244\n",
            "Epoch 225/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3799 - accuracy: 0.8748 - val_loss: 0.7865 - val_accuracy: 0.7585\n",
            "Epoch 226/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.4005 - accuracy: 0.8767 - val_loss: 0.7559 - val_accuracy: 0.7537\n",
            "Epoch 227/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3703 - accuracy: 0.8803 - val_loss: 0.7832 - val_accuracy: 0.7683\n",
            "Epoch 228/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3458 - accuracy: 0.8779 - val_loss: 0.8401 - val_accuracy: 0.7488\n",
            "Epoch 229/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3492 - accuracy: 0.8901 - val_loss: 0.7884 - val_accuracy: 0.7537\n",
            "Epoch 230/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3827 - accuracy: 0.8761 - val_loss: 0.8967 - val_accuracy: 0.7415\n",
            "Epoch 231/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3553 - accuracy: 0.8852 - val_loss: 0.7445 - val_accuracy: 0.7805\n",
            "Epoch 232/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3359 - accuracy: 0.8822 - val_loss: 0.8631 - val_accuracy: 0.7390\n",
            "Epoch 233/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3500 - accuracy: 0.8822 - val_loss: 0.8484 - val_accuracy: 0.7585\n",
            "Epoch 234/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3111 - accuracy: 0.9005 - val_loss: 0.7356 - val_accuracy: 0.7805\n",
            "Epoch 235/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3118 - accuracy: 0.8962 - val_loss: 0.7785 - val_accuracy: 0.7610\n",
            "Epoch 236/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3343 - accuracy: 0.8895 - val_loss: 0.7431 - val_accuracy: 0.7561\n",
            "Epoch 237/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3348 - accuracy: 0.8883 - val_loss: 0.8480 - val_accuracy: 0.7512\n",
            "Epoch 238/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3981 - accuracy: 0.8748 - val_loss: 0.8295 - val_accuracy: 0.7512\n",
            "Epoch 239/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3334 - accuracy: 0.8852 - val_loss: 0.8146 - val_accuracy: 0.7512\n",
            "Epoch 240/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3045 - accuracy: 0.8913 - val_loss: 0.7985 - val_accuracy: 0.7439\n",
            "Epoch 241/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3331 - accuracy: 0.8950 - val_loss: 0.7938 - val_accuracy: 0.7537\n",
            "Epoch 242/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3459 - accuracy: 0.8901 - val_loss: 0.8988 - val_accuracy: 0.7317\n",
            "Epoch 243/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3372 - accuracy: 0.8871 - val_loss: 0.7479 - val_accuracy: 0.7512\n",
            "Epoch 244/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3553 - accuracy: 0.8974 - val_loss: 0.7474 - val_accuracy: 0.7732\n",
            "Epoch 245/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3041 - accuracy: 0.9029 - val_loss: 0.8675 - val_accuracy: 0.7366\n",
            "Epoch 246/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3092 - accuracy: 0.8944 - val_loss: 0.7238 - val_accuracy: 0.7780\n",
            "Epoch 247/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2892 - accuracy: 0.9078 - val_loss: 0.7801 - val_accuracy: 0.7805\n",
            "Epoch 248/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3223 - accuracy: 0.9011 - val_loss: 0.8174 - val_accuracy: 0.7683\n",
            "Epoch 249/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3470 - accuracy: 0.8840 - val_loss: 0.7662 - val_accuracy: 0.7561\n",
            "Epoch 250/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3334 - accuracy: 0.8962 - val_loss: 0.7474 - val_accuracy: 0.7683\n",
            "Epoch 251/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3168 - accuracy: 0.8980 - val_loss: 0.8498 - val_accuracy: 0.7463\n",
            "Epoch 252/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3370 - accuracy: 0.8987 - val_loss: 0.8022 - val_accuracy: 0.7561\n",
            "Epoch 253/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3421 - accuracy: 0.8895 - val_loss: 0.7781 - val_accuracy: 0.7634\n",
            "Epoch 254/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3254 - accuracy: 0.8950 - val_loss: 0.7981 - val_accuracy: 0.7707\n",
            "Epoch 255/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3085 - accuracy: 0.9042 - val_loss: 0.7126 - val_accuracy: 0.7780\n",
            "Epoch 256/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2936 - accuracy: 0.9060 - val_loss: 0.8170 - val_accuracy: 0.7537\n",
            "Epoch 257/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3508 - accuracy: 0.8913 - val_loss: 0.8073 - val_accuracy: 0.7659\n",
            "Epoch 258/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2980 - accuracy: 0.9035 - val_loss: 0.8286 - val_accuracy: 0.7439\n",
            "Epoch 259/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3117 - accuracy: 0.9011 - val_loss: 0.7711 - val_accuracy: 0.7659\n",
            "Epoch 260/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2949 - accuracy: 0.9090 - val_loss: 0.7541 - val_accuracy: 0.7829\n",
            "Epoch 261/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3230 - accuracy: 0.8858 - val_loss: 0.8156 - val_accuracy: 0.7610\n",
            "Epoch 262/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2756 - accuracy: 0.8993 - val_loss: 0.7800 - val_accuracy: 0.7707\n",
            "Epoch 263/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3070 - accuracy: 0.8962 - val_loss: 0.7671 - val_accuracy: 0.7707\n",
            "Epoch 264/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2577 - accuracy: 0.9145 - val_loss: 0.8745 - val_accuracy: 0.7415\n",
            "Epoch 265/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3124 - accuracy: 0.8950 - val_loss: 0.7788 - val_accuracy: 0.7585\n",
            "Epoch 266/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3160 - accuracy: 0.8974 - val_loss: 0.8170 - val_accuracy: 0.7732\n",
            "Epoch 267/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2831 - accuracy: 0.9090 - val_loss: 0.7896 - val_accuracy: 0.7707\n",
            "Epoch 268/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3047 - accuracy: 0.9011 - val_loss: 0.8343 - val_accuracy: 0.7585\n",
            "Epoch 269/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3267 - accuracy: 0.9029 - val_loss: 0.8054 - val_accuracy: 0.7585\n",
            "Epoch 270/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2946 - accuracy: 0.9042 - val_loss: 0.7130 - val_accuracy: 0.7854\n",
            "Epoch 271/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2547 - accuracy: 0.9158 - val_loss: 0.7432 - val_accuracy: 0.7829\n",
            "Epoch 272/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2728 - accuracy: 0.9103 - val_loss: 0.8083 - val_accuracy: 0.7756\n",
            "Epoch 273/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2749 - accuracy: 0.9109 - val_loss: 0.8012 - val_accuracy: 0.7780\n",
            "Epoch 274/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2794 - accuracy: 0.9054 - val_loss: 0.7988 - val_accuracy: 0.7707\n",
            "Epoch 275/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2633 - accuracy: 0.9127 - val_loss: 0.8085 - val_accuracy: 0.7854\n",
            "Epoch 276/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2634 - accuracy: 0.9145 - val_loss: 0.7372 - val_accuracy: 0.7878\n",
            "Epoch 277/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3423 - accuracy: 0.8883 - val_loss: 0.8532 - val_accuracy: 0.7561\n",
            "Epoch 278/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2889 - accuracy: 0.9029 - val_loss: 0.7340 - val_accuracy: 0.7951\n",
            "Epoch 279/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2919 - accuracy: 0.9096 - val_loss: 0.8335 - val_accuracy: 0.7610\n",
            "Epoch 280/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3237 - accuracy: 0.8907 - val_loss: 0.8351 - val_accuracy: 0.7439\n",
            "Epoch 281/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2577 - accuracy: 0.9109 - val_loss: 0.7753 - val_accuracy: 0.7634\n",
            "Epoch 282/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2703 - accuracy: 0.9206 - val_loss: 0.7648 - val_accuracy: 0.7683\n",
            "Epoch 283/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2724 - accuracy: 0.9133 - val_loss: 0.9127 - val_accuracy: 0.7439\n",
            "Epoch 284/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2804 - accuracy: 0.9060 - val_loss: 0.7772 - val_accuracy: 0.7561\n",
            "Epoch 285/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3128 - accuracy: 0.9090 - val_loss: 0.7404 - val_accuracy: 0.7659\n",
            "Epoch 286/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2796 - accuracy: 0.9127 - val_loss: 0.7915 - val_accuracy: 0.7780\n",
            "Epoch 287/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2823 - accuracy: 0.9090 - val_loss: 0.7309 - val_accuracy: 0.7805\n",
            "Epoch 288/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2571 - accuracy: 0.9151 - val_loss: 0.7636 - val_accuracy: 0.7902\n",
            "Epoch 289/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2839 - accuracy: 0.9115 - val_loss: 0.8447 - val_accuracy: 0.7561\n",
            "Epoch 290/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2972 - accuracy: 0.9048 - val_loss: 0.8154 - val_accuracy: 0.7561\n",
            "Epoch 291/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2789 - accuracy: 0.9084 - val_loss: 0.9323 - val_accuracy: 0.7268\n",
            "Epoch 292/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2956 - accuracy: 0.9054 - val_loss: 0.8057 - val_accuracy: 0.7659\n",
            "Epoch 293/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2865 - accuracy: 0.9182 - val_loss: 0.9693 - val_accuracy: 0.7146\n",
            "Epoch 294/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2528 - accuracy: 0.9164 - val_loss: 0.7831 - val_accuracy: 0.7707\n",
            "Epoch 295/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2630 - accuracy: 0.9103 - val_loss: 0.7573 - val_accuracy: 0.7756\n",
            "Epoch 296/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2477 - accuracy: 0.9188 - val_loss: 0.8008 - val_accuracy: 0.7659\n",
            "Epoch 297/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3060 - accuracy: 0.9005 - val_loss: 0.7664 - val_accuracy: 0.7707\n",
            "Epoch 298/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3115 - accuracy: 0.8956 - val_loss: 0.7437 - val_accuracy: 0.7610\n",
            "Epoch 299/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2843 - accuracy: 0.9084 - val_loss: 0.9435 - val_accuracy: 0.7098\n",
            "Epoch 300/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2899 - accuracy: 0.9035 - val_loss: 0.7519 - val_accuracy: 0.7732\n",
            "Epoch 301/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2665 - accuracy: 0.9176 - val_loss: 0.7190 - val_accuracy: 0.7878\n",
            "Epoch 302/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2651 - accuracy: 0.9127 - val_loss: 0.7987 - val_accuracy: 0.7561\n",
            "Epoch 303/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2398 - accuracy: 0.9206 - val_loss: 0.8441 - val_accuracy: 0.7585\n",
            "Epoch 304/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2931 - accuracy: 0.9109 - val_loss: 0.7706 - val_accuracy: 0.7634\n",
            "Epoch 305/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2699 - accuracy: 0.9170 - val_loss: 0.7714 - val_accuracy: 0.7634\n",
            "Epoch 306/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2514 - accuracy: 0.9200 - val_loss: 0.7653 - val_accuracy: 0.7927\n",
            "Epoch 307/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2679 - accuracy: 0.9139 - val_loss: 0.7956 - val_accuracy: 0.7707\n",
            "Epoch 308/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3304 - accuracy: 0.9060 - val_loss: 0.7713 - val_accuracy: 0.7732\n",
            "Epoch 309/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2655 - accuracy: 0.9182 - val_loss: 0.7794 - val_accuracy: 0.7659\n",
            "Epoch 310/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2611 - accuracy: 0.9145 - val_loss: 0.8054 - val_accuracy: 0.7659\n",
            "Epoch 311/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3055 - accuracy: 0.9048 - val_loss: 0.7588 - val_accuracy: 0.7610\n",
            "Epoch 312/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2721 - accuracy: 0.9103 - val_loss: 0.6965 - val_accuracy: 0.7634\n",
            "Epoch 313/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2177 - accuracy: 0.9249 - val_loss: 0.7763 - val_accuracy: 0.7707\n",
            "Epoch 314/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2505 - accuracy: 0.9212 - val_loss: 0.8129 - val_accuracy: 0.7707\n",
            "Epoch 315/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2575 - accuracy: 0.9200 - val_loss: 0.7906 - val_accuracy: 0.7756\n",
            "Epoch 316/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3315 - accuracy: 0.8926 - val_loss: 0.7304 - val_accuracy: 0.7927\n",
            "Epoch 317/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2947 - accuracy: 0.9017 - val_loss: 0.7542 - val_accuracy: 0.7634\n",
            "Epoch 318/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2609 - accuracy: 0.9151 - val_loss: 0.7520 - val_accuracy: 0.7683\n",
            "Epoch 319/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2635 - accuracy: 0.9151 - val_loss: 0.7992 - val_accuracy: 0.7634\n",
            "Epoch 320/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2487 - accuracy: 0.9170 - val_loss: 0.7878 - val_accuracy: 0.7780\n",
            "Epoch 321/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2678 - accuracy: 0.9145 - val_loss: 0.8188 - val_accuracy: 0.7659\n",
            "Epoch 322/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2370 - accuracy: 0.9243 - val_loss: 0.7499 - val_accuracy: 0.7878\n",
            "Epoch 323/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2366 - accuracy: 0.9261 - val_loss: 0.8032 - val_accuracy: 0.7780\n",
            "Epoch 324/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2270 - accuracy: 0.9280 - val_loss: 0.7136 - val_accuracy: 0.7854\n",
            "Epoch 325/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2826 - accuracy: 0.9084 - val_loss: 0.8420 - val_accuracy: 0.7537\n",
            "Epoch 326/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2322 - accuracy: 0.9255 - val_loss: 0.7704 - val_accuracy: 0.7854\n",
            "Epoch 327/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2583 - accuracy: 0.9243 - val_loss: 0.7780 - val_accuracy: 0.7976\n",
            "Epoch 328/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2646 - accuracy: 0.9188 - val_loss: 0.8123 - val_accuracy: 0.7561\n",
            "Epoch 329/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2704 - accuracy: 0.9109 - val_loss: 0.7543 - val_accuracy: 0.7707\n",
            "Epoch 330/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2458 - accuracy: 0.9237 - val_loss: 0.8219 - val_accuracy: 0.7732\n",
            "Epoch 331/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2647 - accuracy: 0.9151 - val_loss: 0.7831 - val_accuracy: 0.7756\n",
            "Epoch 332/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2644 - accuracy: 0.9212 - val_loss: 0.9236 - val_accuracy: 0.7317\n",
            "Epoch 333/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2592 - accuracy: 0.9103 - val_loss: 0.7414 - val_accuracy: 0.7683\n",
            "Epoch 334/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2130 - accuracy: 0.9292 - val_loss: 0.7571 - val_accuracy: 0.7878\n",
            "Epoch 335/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2437 - accuracy: 0.9194 - val_loss: 0.7997 - val_accuracy: 0.7683\n",
            "Epoch 336/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2015 - accuracy: 0.9328 - val_loss: 0.8009 - val_accuracy: 0.7780\n",
            "Epoch 337/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2571 - accuracy: 0.9188 - val_loss: 0.8141 - val_accuracy: 0.7756\n",
            "Epoch 338/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2708 - accuracy: 0.9194 - val_loss: 0.8051 - val_accuracy: 0.7780\n",
            "Epoch 339/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2631 - accuracy: 0.9054 - val_loss: 0.8861 - val_accuracy: 0.7610\n",
            "Epoch 340/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2837 - accuracy: 0.9151 - val_loss: 0.7828 - val_accuracy: 0.7829\n",
            "Epoch 341/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2559 - accuracy: 0.9170 - val_loss: 0.7703 - val_accuracy: 0.7902\n",
            "Epoch 342/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2376 - accuracy: 0.9194 - val_loss: 0.8192 - val_accuracy: 0.7634\n",
            "Epoch 343/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2907 - accuracy: 0.9109 - val_loss: 0.8393 - val_accuracy: 0.7585\n",
            "Epoch 344/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2653 - accuracy: 0.9188 - val_loss: 0.7930 - val_accuracy: 0.7878\n",
            "Epoch 345/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2306 - accuracy: 0.9316 - val_loss: 0.8477 - val_accuracy: 0.7659\n",
            "Epoch 346/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2395 - accuracy: 0.9267 - val_loss: 0.8148 - val_accuracy: 0.7659\n",
            "Epoch 347/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2274 - accuracy: 0.9255 - val_loss: 0.8321 - val_accuracy: 0.7732\n",
            "Epoch 348/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2444 - accuracy: 0.9255 - val_loss: 0.8133 - val_accuracy: 0.7805\n",
            "Epoch 349/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2313 - accuracy: 0.9292 - val_loss: 0.7934 - val_accuracy: 0.7634\n",
            "Epoch 350/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2340 - accuracy: 0.9261 - val_loss: 0.8822 - val_accuracy: 0.7707\n",
            "Epoch 351/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2531 - accuracy: 0.9200 - val_loss: 0.8840 - val_accuracy: 0.7634\n",
            "Epoch 352/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2837 - accuracy: 0.9103 - val_loss: 0.9101 - val_accuracy: 0.7634\n",
            "Epoch 353/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2239 - accuracy: 0.9292 - val_loss: 0.8168 - val_accuracy: 0.7878\n",
            "Epoch 354/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2129 - accuracy: 0.9304 - val_loss: 0.8654 - val_accuracy: 0.7707\n",
            "Epoch 355/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2766 - accuracy: 0.9200 - val_loss: 0.9583 - val_accuracy: 0.7585\n",
            "Epoch 356/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2583 - accuracy: 0.9188 - val_loss: 0.7877 - val_accuracy: 0.7829\n",
            "Epoch 357/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3229 - accuracy: 0.9035 - val_loss: 0.7745 - val_accuracy: 0.7732\n",
            "Epoch 358/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2581 - accuracy: 0.9151 - val_loss: 0.7792 - val_accuracy: 0.7634\n",
            "Epoch 359/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2632 - accuracy: 0.9188 - val_loss: 0.8674 - val_accuracy: 0.7463\n",
            "Epoch 360/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2235 - accuracy: 0.9280 - val_loss: 0.9252 - val_accuracy: 0.7537\n",
            "Epoch 361/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2874 - accuracy: 0.9084 - val_loss: 1.0547 - val_accuracy: 0.6780\n",
            "Epoch 362/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2710 - accuracy: 0.9158 - val_loss: 0.8851 - val_accuracy: 0.7610\n",
            "Epoch 363/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2420 - accuracy: 0.9261 - val_loss: 0.7979 - val_accuracy: 0.7732\n",
            "Epoch 364/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2417 - accuracy: 0.9225 - val_loss: 0.7639 - val_accuracy: 0.7902\n",
            "Epoch 365/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2277 - accuracy: 0.9249 - val_loss: 0.7923 - val_accuracy: 0.7585\n",
            "Epoch 366/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2536 - accuracy: 0.9194 - val_loss: 0.7056 - val_accuracy: 0.7902\n",
            "Epoch 367/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2325 - accuracy: 0.9267 - val_loss: 0.7007 - val_accuracy: 0.7854\n",
            "Epoch 368/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2398 - accuracy: 0.9249 - val_loss: 0.7596 - val_accuracy: 0.7805\n",
            "Epoch 369/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2247 - accuracy: 0.9280 - val_loss: 0.7999 - val_accuracy: 0.7634\n",
            "Epoch 370/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2067 - accuracy: 0.9347 - val_loss: 0.7749 - val_accuracy: 0.7805\n",
            "Epoch 371/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2436 - accuracy: 0.9225 - val_loss: 0.8494 - val_accuracy: 0.7488\n",
            "Epoch 372/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2511 - accuracy: 0.9194 - val_loss: 0.8347 - val_accuracy: 0.7463\n",
            "Epoch 373/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2137 - accuracy: 0.9286 - val_loss: 0.7397 - val_accuracy: 0.7756\n",
            "Epoch 374/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2574 - accuracy: 0.9219 - val_loss: 0.9569 - val_accuracy: 0.7146\n",
            "Epoch 375/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2451 - accuracy: 0.9310 - val_loss: 0.8058 - val_accuracy: 0.7683\n",
            "Epoch 376/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2082 - accuracy: 0.9328 - val_loss: 0.8536 - val_accuracy: 0.7683\n",
            "Epoch 377/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2342 - accuracy: 0.9280 - val_loss: 0.8756 - val_accuracy: 0.7512\n",
            "Epoch 378/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1925 - accuracy: 0.9359 - val_loss: 0.7175 - val_accuracy: 0.7878\n",
            "Epoch 379/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2152 - accuracy: 0.9328 - val_loss: 0.7616 - val_accuracy: 0.7878\n",
            "Epoch 380/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2328 - accuracy: 0.9347 - val_loss: 0.8143 - val_accuracy: 0.7805\n",
            "Epoch 381/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2126 - accuracy: 0.9316 - val_loss: 0.7866 - val_accuracy: 0.7829\n",
            "Epoch 382/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2103 - accuracy: 0.9353 - val_loss: 0.7925 - val_accuracy: 0.7707\n",
            "Epoch 383/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2124 - accuracy: 0.9347 - val_loss: 0.8202 - val_accuracy: 0.7610\n",
            "Epoch 384/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2360 - accuracy: 0.9255 - val_loss: 0.9300 - val_accuracy: 0.7341\n",
            "Epoch 385/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2139 - accuracy: 0.9310 - val_loss: 0.8162 - val_accuracy: 0.7585\n",
            "Epoch 386/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2169 - accuracy: 0.9292 - val_loss: 0.8703 - val_accuracy: 0.7561\n",
            "Epoch 387/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1849 - accuracy: 0.9396 - val_loss: 0.9272 - val_accuracy: 0.7439\n",
            "Epoch 388/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1987 - accuracy: 0.9420 - val_loss: 0.8376 - val_accuracy: 0.7756\n",
            "Epoch 389/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2549 - accuracy: 0.9225 - val_loss: 0.8668 - val_accuracy: 0.7537\n",
            "Epoch 390/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2614 - accuracy: 0.9170 - val_loss: 0.7400 - val_accuracy: 0.7927\n",
            "Epoch 391/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2378 - accuracy: 0.9341 - val_loss: 0.8469 - val_accuracy: 0.7659\n",
            "Epoch 392/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2220 - accuracy: 0.9322 - val_loss: 0.8149 - val_accuracy: 0.7659\n",
            "Epoch 393/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2171 - accuracy: 0.9353 - val_loss: 0.7879 - val_accuracy: 0.7829\n",
            "Epoch 394/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2062 - accuracy: 0.9371 - val_loss: 0.8699 - val_accuracy: 0.7683\n",
            "Epoch 395/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1927 - accuracy: 0.9383 - val_loss: 0.8636 - val_accuracy: 0.7561\n",
            "Epoch 396/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2069 - accuracy: 0.9383 - val_loss: 0.8070 - val_accuracy: 0.7780\n",
            "Epoch 397/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2315 - accuracy: 0.9310 - val_loss: 0.8334 - val_accuracy: 0.7610\n",
            "Epoch 398/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2201 - accuracy: 0.9316 - val_loss: 0.8382 - val_accuracy: 0.7488\n",
            "Epoch 399/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1695 - accuracy: 0.9475 - val_loss: 0.8343 - val_accuracy: 0.7902\n",
            "Epoch 400/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2409 - accuracy: 0.9231 - val_loss: 0.7675 - val_accuracy: 0.7854\n",
            "Epoch 401/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2409 - accuracy: 0.9341 - val_loss: 0.8693 - val_accuracy: 0.7415\n",
            "Epoch 402/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2438 - accuracy: 0.9249 - val_loss: 0.7228 - val_accuracy: 0.7805\n",
            "Epoch 403/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2463 - accuracy: 0.9206 - val_loss: 0.7333 - val_accuracy: 0.7854\n",
            "Epoch 404/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1892 - accuracy: 0.9402 - val_loss: 0.8524 - val_accuracy: 0.7366\n",
            "Epoch 405/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2346 - accuracy: 0.9231 - val_loss: 0.7569 - val_accuracy: 0.7902\n",
            "Epoch 406/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2305 - accuracy: 0.9304 - val_loss: 0.8591 - val_accuracy: 0.7512\n",
            "Epoch 407/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2205 - accuracy: 0.9261 - val_loss: 0.7905 - val_accuracy: 0.7878\n",
            "Epoch 408/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2270 - accuracy: 0.9322 - val_loss: 0.7737 - val_accuracy: 0.7634\n",
            "Epoch 409/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2026 - accuracy: 0.9377 - val_loss: 0.8778 - val_accuracy: 0.7488\n",
            "Epoch 410/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2131 - accuracy: 0.9261 - val_loss: 0.7256 - val_accuracy: 0.7805\n",
            "Epoch 411/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2036 - accuracy: 0.9328 - val_loss: 0.7214 - val_accuracy: 0.7854\n",
            "Epoch 412/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1642 - accuracy: 0.9481 - val_loss: 0.7249 - val_accuracy: 0.8049\n",
            "Epoch 413/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1945 - accuracy: 0.9359 - val_loss: 0.8310 - val_accuracy: 0.7683\n",
            "Epoch 414/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2196 - accuracy: 0.9316 - val_loss: 0.8545 - val_accuracy: 0.7537\n",
            "Epoch 415/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2352 - accuracy: 0.9286 - val_loss: 0.8046 - val_accuracy: 0.7732\n",
            "Epoch 416/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2555 - accuracy: 0.9231 - val_loss: 0.7991 - val_accuracy: 0.7683\n",
            "Epoch 417/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2094 - accuracy: 0.9371 - val_loss: 0.8926 - val_accuracy: 0.7585\n",
            "Epoch 418/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2200 - accuracy: 0.9359 - val_loss: 0.8141 - val_accuracy: 0.7732\n",
            "Epoch 419/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1974 - accuracy: 0.9396 - val_loss: 0.8609 - val_accuracy: 0.7659\n",
            "Epoch 420/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2369 - accuracy: 0.9304 - val_loss: 0.8728 - val_accuracy: 0.7634\n",
            "Epoch 421/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2343 - accuracy: 0.9304 - val_loss: 1.0263 - val_accuracy: 0.7512\n",
            "Epoch 422/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2130 - accuracy: 0.9316 - val_loss: 0.7794 - val_accuracy: 0.7707\n",
            "Epoch 423/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2356 - accuracy: 0.9304 - val_loss: 0.7817 - val_accuracy: 0.7756\n",
            "Epoch 424/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2159 - accuracy: 0.9328 - val_loss: 0.8707 - val_accuracy: 0.7659\n",
            "Epoch 425/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2576 - accuracy: 0.9243 - val_loss: 0.8454 - val_accuracy: 0.7439\n",
            "Epoch 426/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2163 - accuracy: 0.9322 - val_loss: 0.8606 - val_accuracy: 0.7756\n",
            "Epoch 427/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2507 - accuracy: 0.9231 - val_loss: 0.9389 - val_accuracy: 0.7463\n",
            "Epoch 428/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2007 - accuracy: 0.9383 - val_loss: 0.8472 - val_accuracy: 0.7732\n",
            "Epoch 429/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2106 - accuracy: 0.9383 - val_loss: 0.8642 - val_accuracy: 0.7707\n",
            "Epoch 430/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2231 - accuracy: 0.9310 - val_loss: 0.8059 - val_accuracy: 0.7854\n",
            "Epoch 431/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1920 - accuracy: 0.9408 - val_loss: 0.8720 - val_accuracy: 0.7707\n",
            "Epoch 432/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2153 - accuracy: 0.9359 - val_loss: 0.8082 - val_accuracy: 0.7683\n",
            "Epoch 433/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1791 - accuracy: 0.9389 - val_loss: 0.7458 - val_accuracy: 0.7854\n",
            "Epoch 434/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2214 - accuracy: 0.9347 - val_loss: 0.7418 - val_accuracy: 0.7951\n",
            "Epoch 435/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2241 - accuracy: 0.9292 - val_loss: 0.6976 - val_accuracy: 0.7854\n",
            "Epoch 436/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1964 - accuracy: 0.9347 - val_loss: 0.7332 - val_accuracy: 0.7854\n",
            "Epoch 437/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2381 - accuracy: 0.9292 - val_loss: 0.7463 - val_accuracy: 0.7976\n",
            "Epoch 438/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2378 - accuracy: 0.9280 - val_loss: 0.6817 - val_accuracy: 0.8049\n",
            "Epoch 439/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1999 - accuracy: 0.9310 - val_loss: 0.7588 - val_accuracy: 0.7878\n",
            "Epoch 440/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2167 - accuracy: 0.9328 - val_loss: 0.8837 - val_accuracy: 0.7707\n",
            "Epoch 441/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2174 - accuracy: 0.9304 - val_loss: 0.8304 - val_accuracy: 0.7780\n",
            "Epoch 442/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2411 - accuracy: 0.9249 - val_loss: 0.9456 - val_accuracy: 0.7488\n",
            "Epoch 443/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2045 - accuracy: 0.9359 - val_loss: 0.9262 - val_accuracy: 0.7537\n",
            "Epoch 444/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2108 - accuracy: 0.9408 - val_loss: 0.8329 - val_accuracy: 0.7634\n",
            "Epoch 445/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2447 - accuracy: 0.9328 - val_loss: 0.7541 - val_accuracy: 0.7902\n",
            "Epoch 446/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2146 - accuracy: 0.9377 - val_loss: 0.7955 - val_accuracy: 0.7805\n",
            "Epoch 447/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2031 - accuracy: 0.9365 - val_loss: 0.7196 - val_accuracy: 0.7829\n",
            "Epoch 448/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2094 - accuracy: 0.9274 - val_loss: 0.7499 - val_accuracy: 0.7902\n",
            "Epoch 449/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2083 - accuracy: 0.9408 - val_loss: 0.7520 - val_accuracy: 0.7780\n",
            "Epoch 450/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2078 - accuracy: 0.9292 - val_loss: 0.7725 - val_accuracy: 0.7610\n",
            "Epoch 451/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2636 - accuracy: 0.9298 - val_loss: 0.8158 - val_accuracy: 0.7707\n",
            "Epoch 452/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2247 - accuracy: 0.9328 - val_loss: 0.7927 - val_accuracy: 0.7659\n",
            "Epoch 453/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2330 - accuracy: 0.9304 - val_loss: 0.7502 - val_accuracy: 0.7756\n",
            "Epoch 454/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2124 - accuracy: 0.9371 - val_loss: 0.7129 - val_accuracy: 0.8024\n",
            "Epoch 455/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2110 - accuracy: 0.9261 - val_loss: 0.7538 - val_accuracy: 0.7829\n",
            "Epoch 456/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1698 - accuracy: 0.9451 - val_loss: 0.8338 - val_accuracy: 0.7756\n",
            "Epoch 457/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2201 - accuracy: 0.9383 - val_loss: 0.8111 - val_accuracy: 0.7610\n",
            "Epoch 458/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2290 - accuracy: 0.9353 - val_loss: 0.6772 - val_accuracy: 0.8049\n",
            "Epoch 459/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2182 - accuracy: 0.9267 - val_loss: 0.7742 - val_accuracy: 0.7854\n",
            "Epoch 460/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1857 - accuracy: 0.9353 - val_loss: 0.8606 - val_accuracy: 0.7512\n",
            "Epoch 461/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1988 - accuracy: 0.9389 - val_loss: 0.7791 - val_accuracy: 0.7878\n",
            "Epoch 462/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2182 - accuracy: 0.9414 - val_loss: 0.8847 - val_accuracy: 0.7561\n",
            "Epoch 463/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2072 - accuracy: 0.9286 - val_loss: 0.7809 - val_accuracy: 0.8000\n",
            "Epoch 464/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1980 - accuracy: 0.9389 - val_loss: 0.7914 - val_accuracy: 0.7707\n",
            "Epoch 465/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1851 - accuracy: 0.9426 - val_loss: 0.7366 - val_accuracy: 0.7829\n",
            "Epoch 466/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2066 - accuracy: 0.9371 - val_loss: 0.7550 - val_accuracy: 0.7902\n",
            "Epoch 467/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2101 - accuracy: 0.9255 - val_loss: 0.7907 - val_accuracy: 0.7707\n",
            "Epoch 468/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2002 - accuracy: 0.9396 - val_loss: 0.7062 - val_accuracy: 0.7659\n",
            "Epoch 469/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1530 - accuracy: 0.9451 - val_loss: 0.7587 - val_accuracy: 0.7829\n",
            "Epoch 470/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2174 - accuracy: 0.9353 - val_loss: 0.7981 - val_accuracy: 0.7829\n",
            "Epoch 471/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2016 - accuracy: 0.9420 - val_loss: 0.7749 - val_accuracy: 0.7805\n",
            "Epoch 472/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2008 - accuracy: 0.9414 - val_loss: 0.7644 - val_accuracy: 0.7829\n",
            "Epoch 473/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1914 - accuracy: 0.9463 - val_loss: 0.9482 - val_accuracy: 0.7585\n",
            "Epoch 474/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2054 - accuracy: 0.9335 - val_loss: 0.9319 - val_accuracy: 0.7683\n",
            "Epoch 475/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2032 - accuracy: 0.9365 - val_loss: 0.8664 - val_accuracy: 0.7585\n",
            "Epoch 476/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2318 - accuracy: 0.9286 - val_loss: 0.7600 - val_accuracy: 0.7854\n",
            "Epoch 477/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2292 - accuracy: 0.9249 - val_loss: 0.7489 - val_accuracy: 0.7902\n",
            "Epoch 478/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2111 - accuracy: 0.9371 - val_loss: 0.7946 - val_accuracy: 0.7756\n",
            "Epoch 479/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2123 - accuracy: 0.9310 - val_loss: 0.7019 - val_accuracy: 0.7805\n",
            "Epoch 480/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2054 - accuracy: 0.9359 - val_loss: 0.7812 - val_accuracy: 0.7756\n",
            "Epoch 481/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2033 - accuracy: 0.9389 - val_loss: 0.7407 - val_accuracy: 0.7732\n",
            "Epoch 482/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1646 - accuracy: 0.9438 - val_loss: 0.7449 - val_accuracy: 0.7780\n",
            "Epoch 483/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2283 - accuracy: 0.9328 - val_loss: 0.9457 - val_accuracy: 0.7366\n",
            "Epoch 484/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2048 - accuracy: 0.9353 - val_loss: 0.8050 - val_accuracy: 0.7683\n",
            "Epoch 485/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2265 - accuracy: 0.9389 - val_loss: 0.8435 - val_accuracy: 0.7732\n",
            "Epoch 486/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1781 - accuracy: 0.9487 - val_loss: 0.7909 - val_accuracy: 0.7805\n",
            "Epoch 487/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2211 - accuracy: 0.9316 - val_loss: 0.8187 - val_accuracy: 0.7537\n",
            "Epoch 488/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1735 - accuracy: 0.9463 - val_loss: 0.7703 - val_accuracy: 0.7854\n",
            "Epoch 489/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2206 - accuracy: 0.9365 - val_loss: 1.0653 - val_accuracy: 0.7073\n",
            "Epoch 490/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1989 - accuracy: 0.9451 - val_loss: 0.7213 - val_accuracy: 0.7780\n",
            "Epoch 491/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1560 - accuracy: 0.9512 - val_loss: 0.8176 - val_accuracy: 0.7805\n",
            "Epoch 492/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1684 - accuracy: 0.9481 - val_loss: 0.8528 - val_accuracy: 0.7634\n",
            "Epoch 493/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1839 - accuracy: 0.9469 - val_loss: 0.9205 - val_accuracy: 0.7463\n",
            "Epoch 494/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1466 - accuracy: 0.9542 - val_loss: 0.8261 - val_accuracy: 0.7512\n",
            "Epoch 495/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1976 - accuracy: 0.9371 - val_loss: 0.7478 - val_accuracy: 0.7951\n",
            "Epoch 496/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2335 - accuracy: 0.9408 - val_loss: 0.7929 - val_accuracy: 0.7732\n",
            "Epoch 497/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2228 - accuracy: 0.9359 - val_loss: 0.7664 - val_accuracy: 0.7561\n",
            "Epoch 498/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2298 - accuracy: 0.9304 - val_loss: 0.7375 - val_accuracy: 0.7659\n",
            "Epoch 499/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2372 - accuracy: 0.9267 - val_loss: 0.7415 - val_accuracy: 0.7610\n",
            "Epoch 500/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1912 - accuracy: 0.9359 - val_loss: 0.7823 - val_accuracy: 0.7512\n",
            "Epoch 501/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2029 - accuracy: 0.9438 - val_loss: 0.8320 - val_accuracy: 0.7512\n",
            "Epoch 502/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2379 - accuracy: 0.9347 - val_loss: 0.7466 - val_accuracy: 0.7610\n",
            "Epoch 503/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1628 - accuracy: 0.9475 - val_loss: 0.7773 - val_accuracy: 0.7707\n",
            "Epoch 504/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1884 - accuracy: 0.9438 - val_loss: 0.7958 - val_accuracy: 0.7854\n",
            "Epoch 505/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2204 - accuracy: 0.9396 - val_loss: 0.9612 - val_accuracy: 0.7585\n",
            "Epoch 506/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2071 - accuracy: 0.9377 - val_loss: 0.8130 - val_accuracy: 0.7927\n",
            "Epoch 507/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2050 - accuracy: 0.9383 - val_loss: 0.8070 - val_accuracy: 0.8000\n",
            "Epoch 508/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2033 - accuracy: 0.9322 - val_loss: 0.7913 - val_accuracy: 0.7805\n",
            "Epoch 509/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1909 - accuracy: 0.9377 - val_loss: 0.7872 - val_accuracy: 0.7780\n",
            "Epoch 510/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1775 - accuracy: 0.9481 - val_loss: 0.8452 - val_accuracy: 0.7683\n",
            "Epoch 511/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1547 - accuracy: 0.9469 - val_loss: 0.8393 - val_accuracy: 0.7683\n",
            "Epoch 512/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1880 - accuracy: 0.9426 - val_loss: 0.8466 - val_accuracy: 0.7585\n",
            "Epoch 513/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1907 - accuracy: 0.9402 - val_loss: 0.8667 - val_accuracy: 0.7512\n",
            "Epoch 514/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2267 - accuracy: 0.9347 - val_loss: 0.7910 - val_accuracy: 0.7878\n",
            "Epoch 515/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2186 - accuracy: 0.9377 - val_loss: 0.8222 - val_accuracy: 0.7829\n",
            "Epoch 516/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1647 - accuracy: 0.9414 - val_loss: 0.8172 - val_accuracy: 0.7707\n",
            "Epoch 517/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2085 - accuracy: 0.9298 - val_loss: 0.7711 - val_accuracy: 0.7732\n",
            "Epoch 518/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2029 - accuracy: 0.9377 - val_loss: 0.8600 - val_accuracy: 0.7585\n",
            "Epoch 519/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2222 - accuracy: 0.9353 - val_loss: 0.8447 - val_accuracy: 0.7683\n",
            "Epoch 520/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1843 - accuracy: 0.9426 - val_loss: 0.9304 - val_accuracy: 0.7415\n",
            "Epoch 521/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2023 - accuracy: 0.9420 - val_loss: 0.7837 - val_accuracy: 0.7878\n",
            "Epoch 522/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1932 - accuracy: 0.9402 - val_loss: 0.9316 - val_accuracy: 0.7415\n",
            "Epoch 523/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1699 - accuracy: 0.9402 - val_loss: 0.8727 - val_accuracy: 0.7659\n",
            "Epoch 524/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2194 - accuracy: 0.9359 - val_loss: 0.8569 - val_accuracy: 0.7610\n",
            "Epoch 525/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2226 - accuracy: 0.9371 - val_loss: 0.8002 - val_accuracy: 0.7780\n",
            "Epoch 526/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1862 - accuracy: 0.9414 - val_loss: 0.8073 - val_accuracy: 0.7878\n",
            "Epoch 527/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2130 - accuracy: 0.9414 - val_loss: 0.8331 - val_accuracy: 0.7585\n",
            "Epoch 528/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1960 - accuracy: 0.9371 - val_loss: 0.7805 - val_accuracy: 0.7732\n",
            "Epoch 529/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2389 - accuracy: 0.9341 - val_loss: 0.7900 - val_accuracy: 0.7707\n",
            "Epoch 530/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2010 - accuracy: 0.9371 - val_loss: 0.7717 - val_accuracy: 0.7756\n",
            "Epoch 531/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1713 - accuracy: 0.9438 - val_loss: 0.8422 - val_accuracy: 0.7585\n",
            "Epoch 532/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2186 - accuracy: 0.9359 - val_loss: 0.8292 - val_accuracy: 0.7732\n",
            "Epoch 533/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2394 - accuracy: 0.9341 - val_loss: 0.7870 - val_accuracy: 0.7610\n",
            "Epoch 534/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2236 - accuracy: 0.9389 - val_loss: 0.8355 - val_accuracy: 0.7659\n",
            "Epoch 535/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1689 - accuracy: 0.9505 - val_loss: 0.9486 - val_accuracy: 0.7463\n",
            "Epoch 536/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2382 - accuracy: 0.9274 - val_loss: 0.8740 - val_accuracy: 0.7512\n",
            "Epoch 537/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2127 - accuracy: 0.9426 - val_loss: 0.9043 - val_accuracy: 0.7683\n",
            "Epoch 538/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1683 - accuracy: 0.9408 - val_loss: 0.7996 - val_accuracy: 0.7585\n",
            "Epoch 539/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2010 - accuracy: 0.9377 - val_loss: 0.7750 - val_accuracy: 0.7854\n",
            "Epoch 540/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1754 - accuracy: 0.9469 - val_loss: 0.7687 - val_accuracy: 0.7878\n",
            "Epoch 541/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1557 - accuracy: 0.9499 - val_loss: 0.8222 - val_accuracy: 0.7756\n",
            "Epoch 542/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1840 - accuracy: 0.9481 - val_loss: 0.8825 - val_accuracy: 0.7780\n",
            "Epoch 543/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2140 - accuracy: 0.9371 - val_loss: 0.7883 - val_accuracy: 0.7927\n",
            "Epoch 544/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1883 - accuracy: 0.9377 - val_loss: 0.8304 - val_accuracy: 0.7829\n",
            "Epoch 545/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1896 - accuracy: 0.9322 - val_loss: 0.8718 - val_accuracy: 0.7780\n",
            "Epoch 546/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2123 - accuracy: 0.9383 - val_loss: 0.8042 - val_accuracy: 0.7732\n",
            "Epoch 547/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2066 - accuracy: 0.9316 - val_loss: 0.8637 - val_accuracy: 0.7585\n",
            "Epoch 548/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1747 - accuracy: 0.9396 - val_loss: 0.8894 - val_accuracy: 0.7463\n",
            "Epoch 549/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1488 - accuracy: 0.9518 - val_loss: 0.8376 - val_accuracy: 0.7805\n",
            "Epoch 550/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2649 - accuracy: 0.9249 - val_loss: 0.8246 - val_accuracy: 0.7829\n",
            "Epoch 551/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1992 - accuracy: 0.9377 - val_loss: 0.7594 - val_accuracy: 0.7683\n",
            "Epoch 552/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2268 - accuracy: 0.9328 - val_loss: 0.8871 - val_accuracy: 0.7585\n",
            "Epoch 553/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2293 - accuracy: 0.9237 - val_loss: 0.7903 - val_accuracy: 0.7854\n",
            "Epoch 554/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1645 - accuracy: 0.9487 - val_loss: 0.8598 - val_accuracy: 0.7829\n",
            "Epoch 555/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2149 - accuracy: 0.9396 - val_loss: 0.8491 - val_accuracy: 0.7829\n",
            "Epoch 556/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2204 - accuracy: 0.9359 - val_loss: 0.8013 - val_accuracy: 0.7951\n",
            "Epoch 557/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1959 - accuracy: 0.9408 - val_loss: 0.7800 - val_accuracy: 0.7878\n",
            "Epoch 558/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1338 - accuracy: 0.9536 - val_loss: 0.8818 - val_accuracy: 0.7732\n",
            "Epoch 559/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1987 - accuracy: 0.9341 - val_loss: 0.8232 - val_accuracy: 0.7829\n",
            "Epoch 560/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1950 - accuracy: 0.9420 - val_loss: 0.8397 - val_accuracy: 0.7659\n",
            "Epoch 561/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2192 - accuracy: 0.9347 - val_loss: 0.9770 - val_accuracy: 0.7488\n",
            "Epoch 562/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1808 - accuracy: 0.9451 - val_loss: 0.8360 - val_accuracy: 0.7902\n",
            "Epoch 563/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2055 - accuracy: 0.9396 - val_loss: 0.8356 - val_accuracy: 0.7683\n",
            "Epoch 564/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1588 - accuracy: 0.9524 - val_loss: 0.8735 - val_accuracy: 0.7439\n",
            "Epoch 565/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1845 - accuracy: 0.9438 - val_loss: 0.8911 - val_accuracy: 0.7561\n",
            "Epoch 566/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1907 - accuracy: 0.9475 - val_loss: 0.8550 - val_accuracy: 0.7829\n",
            "Epoch 567/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1905 - accuracy: 0.9438 - val_loss: 0.9146 - val_accuracy: 0.7659\n",
            "Epoch 568/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1542 - accuracy: 0.9518 - val_loss: 0.9957 - val_accuracy: 0.7341\n",
            "Epoch 569/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1574 - accuracy: 0.9481 - val_loss: 0.9209 - val_accuracy: 0.7585\n",
            "Epoch 570/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2109 - accuracy: 0.9341 - val_loss: 0.8445 - val_accuracy: 0.7756\n",
            "Epoch 571/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2346 - accuracy: 0.9304 - val_loss: 0.8191 - val_accuracy: 0.7707\n",
            "Epoch 572/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1443 - accuracy: 0.9560 - val_loss: 0.8132 - val_accuracy: 0.7854\n",
            "Epoch 573/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2056 - accuracy: 0.9389 - val_loss: 0.8308 - val_accuracy: 0.7902\n",
            "Epoch 574/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1912 - accuracy: 0.9469 - val_loss: 0.8782 - val_accuracy: 0.7610\n",
            "Epoch 575/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1762 - accuracy: 0.9481 - val_loss: 0.8855 - val_accuracy: 0.7659\n",
            "Epoch 576/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1625 - accuracy: 0.9524 - val_loss: 0.9291 - val_accuracy: 0.7439\n",
            "Epoch 577/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1842 - accuracy: 0.9426 - val_loss: 0.9364 - val_accuracy: 0.7537\n",
            "Epoch 578/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1786 - accuracy: 0.9396 - val_loss: 0.8737 - val_accuracy: 0.7634\n",
            "Epoch 579/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1851 - accuracy: 0.9396 - val_loss: 0.8019 - val_accuracy: 0.7927\n",
            "Epoch 580/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2186 - accuracy: 0.9420 - val_loss: 0.8029 - val_accuracy: 0.7585\n",
            "Epoch 581/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2277 - accuracy: 0.9347 - val_loss: 0.7907 - val_accuracy: 0.7707\n",
            "Epoch 582/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1672 - accuracy: 0.9463 - val_loss: 0.8560 - val_accuracy: 0.7756\n",
            "Epoch 583/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2031 - accuracy: 0.9365 - val_loss: 0.8477 - val_accuracy: 0.7707\n",
            "Epoch 584/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2372 - accuracy: 0.9322 - val_loss: 0.7780 - val_accuracy: 0.7951\n",
            "Epoch 585/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1960 - accuracy: 0.9457 - val_loss: 0.7919 - val_accuracy: 0.7878\n",
            "Epoch 586/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1622 - accuracy: 0.9536 - val_loss: 0.8047 - val_accuracy: 0.7951\n",
            "Epoch 587/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1845 - accuracy: 0.9530 - val_loss: 0.7968 - val_accuracy: 0.8024\n",
            "Epoch 588/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1873 - accuracy: 0.9451 - val_loss: 0.9113 - val_accuracy: 0.7488\n",
            "Epoch 589/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1753 - accuracy: 0.9457 - val_loss: 0.7708 - val_accuracy: 0.7878\n",
            "Epoch 590/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2090 - accuracy: 0.9359 - val_loss: 0.8054 - val_accuracy: 0.7732\n",
            "Epoch 591/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1742 - accuracy: 0.9426 - val_loss: 0.8195 - val_accuracy: 0.7805\n",
            "Epoch 592/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2030 - accuracy: 0.9359 - val_loss: 0.9187 - val_accuracy: 0.7561\n",
            "Epoch 593/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2107 - accuracy: 0.9389 - val_loss: 0.8510 - val_accuracy: 0.7732\n",
            "Epoch 594/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1647 - accuracy: 0.9512 - val_loss: 0.8312 - val_accuracy: 0.7829\n",
            "Epoch 595/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1878 - accuracy: 0.9408 - val_loss: 0.7646 - val_accuracy: 0.7829\n",
            "Epoch 596/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1561 - accuracy: 0.9585 - val_loss: 0.8103 - val_accuracy: 0.7805\n",
            "Epoch 597/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1394 - accuracy: 0.9573 - val_loss: 0.8010 - val_accuracy: 0.7829\n",
            "Epoch 598/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1401 - accuracy: 0.9591 - val_loss: 0.7831 - val_accuracy: 0.7976\n",
            "Epoch 599/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2166 - accuracy: 0.9359 - val_loss: 0.7953 - val_accuracy: 0.7829\n",
            "Epoch 600/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2228 - accuracy: 0.9383 - val_loss: 0.9527 - val_accuracy: 0.7488\n",
            "Epoch 601/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1828 - accuracy: 0.9383 - val_loss: 0.8629 - val_accuracy: 0.7927\n",
            "Epoch 602/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1988 - accuracy: 0.9408 - val_loss: 0.8108 - val_accuracy: 0.7634\n",
            "Epoch 603/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1796 - accuracy: 0.9432 - val_loss: 0.9083 - val_accuracy: 0.7610\n",
            "Epoch 604/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1888 - accuracy: 0.9420 - val_loss: 0.7879 - val_accuracy: 0.7927\n",
            "Epoch 605/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2276 - accuracy: 0.9310 - val_loss: 0.8837 - val_accuracy: 0.7585\n",
            "Epoch 606/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1635 - accuracy: 0.9499 - val_loss: 0.8262 - val_accuracy: 0.7854\n",
            "Epoch 607/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1616 - accuracy: 0.9444 - val_loss: 0.8951 - val_accuracy: 0.7732\n",
            "Epoch 608/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1622 - accuracy: 0.9499 - val_loss: 0.7337 - val_accuracy: 0.7976\n",
            "Epoch 609/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2071 - accuracy: 0.9341 - val_loss: 0.7531 - val_accuracy: 0.7756\n",
            "Epoch 610/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1741 - accuracy: 0.9481 - val_loss: 0.8138 - val_accuracy: 0.7902\n",
            "Epoch 611/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2144 - accuracy: 0.9347 - val_loss: 0.8217 - val_accuracy: 0.7878\n",
            "Epoch 612/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1756 - accuracy: 0.9536 - val_loss: 0.9701 - val_accuracy: 0.7585\n",
            "Epoch 613/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2115 - accuracy: 0.9377 - val_loss: 0.9259 - val_accuracy: 0.7659\n",
            "Epoch 614/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1705 - accuracy: 0.9475 - val_loss: 0.7972 - val_accuracy: 0.8146\n",
            "Epoch 615/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2013 - accuracy: 0.9383 - val_loss: 0.8471 - val_accuracy: 0.8024\n",
            "Epoch 616/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2204 - accuracy: 0.9402 - val_loss: 1.0178 - val_accuracy: 0.7439\n",
            "Epoch 617/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2384 - accuracy: 0.9335 - val_loss: 0.8280 - val_accuracy: 0.7732\n",
            "Epoch 618/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1614 - accuracy: 0.9548 - val_loss: 0.7961 - val_accuracy: 0.8024\n",
            "Epoch 619/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2079 - accuracy: 0.9402 - val_loss: 0.8205 - val_accuracy: 0.8000\n",
            "Epoch 620/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1974 - accuracy: 0.9475 - val_loss: 0.8190 - val_accuracy: 0.7854\n",
            "Epoch 621/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1867 - accuracy: 0.9426 - val_loss: 0.8786 - val_accuracy: 0.7805\n",
            "Epoch 622/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2592 - accuracy: 0.9212 - val_loss: 0.8296 - val_accuracy: 0.7732\n",
            "Epoch 623/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2300 - accuracy: 0.9383 - val_loss: 0.7774 - val_accuracy: 0.7878\n",
            "Epoch 624/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1873 - accuracy: 0.9377 - val_loss: 0.8265 - val_accuracy: 0.7878\n",
            "Epoch 625/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1853 - accuracy: 0.9438 - val_loss: 0.8312 - val_accuracy: 0.7878\n",
            "Epoch 626/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2418 - accuracy: 0.9304 - val_loss: 0.7910 - val_accuracy: 0.7683\n",
            "Epoch 627/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2428 - accuracy: 0.9310 - val_loss: 0.7768 - val_accuracy: 0.7878\n",
            "Epoch 628/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2422 - accuracy: 0.9310 - val_loss: 0.8488 - val_accuracy: 0.7659\n",
            "Epoch 629/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1866 - accuracy: 0.9438 - val_loss: 0.7662 - val_accuracy: 0.7829\n",
            "Epoch 630/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1790 - accuracy: 0.9451 - val_loss: 0.7619 - val_accuracy: 0.7976\n",
            "Epoch 631/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1836 - accuracy: 0.9396 - val_loss: 0.8215 - val_accuracy: 0.7878\n",
            "Epoch 632/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1905 - accuracy: 0.9408 - val_loss: 1.0244 - val_accuracy: 0.7537\n",
            "Epoch 633/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1692 - accuracy: 0.9481 - val_loss: 0.8209 - val_accuracy: 0.7902\n",
            "Epoch 634/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1770 - accuracy: 0.9451 - val_loss: 0.8250 - val_accuracy: 0.7829\n",
            "Epoch 635/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1838 - accuracy: 0.9475 - val_loss: 0.7617 - val_accuracy: 0.7756\n",
            "Epoch 636/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1891 - accuracy: 0.9420 - val_loss: 0.7927 - val_accuracy: 0.7805\n",
            "Epoch 637/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1366 - accuracy: 0.9567 - val_loss: 0.9422 - val_accuracy: 0.7683\n",
            "Epoch 638/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1472 - accuracy: 0.9530 - val_loss: 0.9269 - val_accuracy: 0.7732\n",
            "Epoch 639/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1660 - accuracy: 0.9518 - val_loss: 0.8672 - val_accuracy: 0.7683\n",
            "Epoch 640/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1605 - accuracy: 0.9481 - val_loss: 0.9741 - val_accuracy: 0.7610\n",
            "Epoch 641/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2572 - accuracy: 0.9249 - val_loss: 0.8173 - val_accuracy: 0.7951\n",
            "Epoch 642/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1813 - accuracy: 0.9444 - val_loss: 0.8487 - val_accuracy: 0.7854\n",
            "Epoch 643/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1536 - accuracy: 0.9536 - val_loss: 0.8865 - val_accuracy: 0.7732\n",
            "Epoch 644/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1943 - accuracy: 0.9438 - val_loss: 0.8712 - val_accuracy: 0.7878\n",
            "Epoch 645/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1786 - accuracy: 0.9414 - val_loss: 0.8489 - val_accuracy: 0.7780\n",
            "Epoch 646/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1970 - accuracy: 0.9420 - val_loss: 0.9434 - val_accuracy: 0.7634\n",
            "Epoch 647/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1753 - accuracy: 0.9524 - val_loss: 0.9618 - val_accuracy: 0.7634\n",
            "Epoch 648/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1703 - accuracy: 0.9414 - val_loss: 0.8315 - val_accuracy: 0.7683\n",
            "Epoch 649/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1594 - accuracy: 0.9560 - val_loss: 0.8763 - val_accuracy: 0.7780\n",
            "Epoch 650/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1719 - accuracy: 0.9493 - val_loss: 0.8764 - val_accuracy: 0.7854\n",
            "Epoch 651/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2319 - accuracy: 0.9383 - val_loss: 0.8937 - val_accuracy: 0.7780\n",
            "Epoch 652/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1688 - accuracy: 0.9469 - val_loss: 0.9528 - val_accuracy: 0.7659\n",
            "Epoch 653/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1906 - accuracy: 0.9438 - val_loss: 0.9232 - val_accuracy: 0.7951\n",
            "Epoch 654/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1884 - accuracy: 0.9426 - val_loss: 0.8047 - val_accuracy: 0.7902\n",
            "Epoch 655/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1845 - accuracy: 0.9432 - val_loss: 0.8283 - val_accuracy: 0.8000\n",
            "Epoch 656/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1773 - accuracy: 0.9383 - val_loss: 0.8315 - val_accuracy: 0.8098\n",
            "Epoch 657/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1601 - accuracy: 0.9554 - val_loss: 0.9815 - val_accuracy: 0.7659\n",
            "Epoch 658/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1746 - accuracy: 0.9469 - val_loss: 0.8682 - val_accuracy: 0.7805\n",
            "Epoch 659/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1787 - accuracy: 0.9420 - val_loss: 0.8523 - val_accuracy: 0.7927\n",
            "Epoch 660/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1721 - accuracy: 0.9524 - val_loss: 0.8720 - val_accuracy: 0.7951\n",
            "Epoch 661/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1857 - accuracy: 0.9512 - val_loss: 0.8203 - val_accuracy: 0.7927\n",
            "Epoch 662/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1911 - accuracy: 0.9402 - val_loss: 0.8433 - val_accuracy: 0.7927\n",
            "Epoch 663/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1494 - accuracy: 0.9542 - val_loss: 0.7761 - val_accuracy: 0.8049\n",
            "Epoch 664/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1564 - accuracy: 0.9530 - val_loss: 0.9186 - val_accuracy: 0.7683\n",
            "Epoch 665/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1954 - accuracy: 0.9469 - val_loss: 0.8443 - val_accuracy: 0.7756\n",
            "Epoch 666/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1712 - accuracy: 0.9408 - val_loss: 0.8711 - val_accuracy: 0.7732\n",
            "Epoch 667/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2106 - accuracy: 0.9371 - val_loss: 0.8748 - val_accuracy: 0.7780\n",
            "Epoch 668/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1876 - accuracy: 0.9426 - val_loss: 0.8626 - val_accuracy: 0.7805\n",
            "Epoch 669/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1913 - accuracy: 0.9469 - val_loss: 1.0227 - val_accuracy: 0.7390\n",
            "Epoch 670/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1592 - accuracy: 0.9524 - val_loss: 0.8245 - val_accuracy: 0.7951\n",
            "Epoch 671/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1553 - accuracy: 0.9548 - val_loss: 0.8485 - val_accuracy: 0.7780\n",
            "Epoch 672/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1775 - accuracy: 0.9475 - val_loss: 0.9053 - val_accuracy: 0.7732\n",
            "Epoch 673/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1577 - accuracy: 0.9505 - val_loss: 0.7994 - val_accuracy: 0.7878\n",
            "Epoch 674/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1478 - accuracy: 0.9505 - val_loss: 0.8060 - val_accuracy: 0.7780\n",
            "Epoch 675/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1827 - accuracy: 0.9457 - val_loss: 0.7847 - val_accuracy: 0.7976\n",
            "Epoch 676/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1725 - accuracy: 0.9481 - val_loss: 0.7413 - val_accuracy: 0.7902\n",
            "Epoch 677/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1857 - accuracy: 0.9444 - val_loss: 0.8493 - val_accuracy: 0.7732\n",
            "Epoch 678/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1501 - accuracy: 0.9463 - val_loss: 0.8001 - val_accuracy: 0.8049\n",
            "Epoch 679/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1932 - accuracy: 0.9432 - val_loss: 0.8584 - val_accuracy: 0.7927\n",
            "Epoch 680/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2584 - accuracy: 0.9261 - val_loss: 0.8361 - val_accuracy: 0.7683\n",
            "Epoch 681/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1794 - accuracy: 0.9438 - val_loss: 0.8311 - val_accuracy: 0.7878\n",
            "Epoch 682/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1777 - accuracy: 0.9475 - val_loss: 0.8560 - val_accuracy: 0.7854\n",
            "Epoch 683/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2279 - accuracy: 0.9341 - val_loss: 0.7594 - val_accuracy: 0.7829\n",
            "Epoch 684/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1863 - accuracy: 0.9438 - val_loss: 0.9217 - val_accuracy: 0.7463\n",
            "Epoch 685/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1695 - accuracy: 0.9536 - val_loss: 0.8568 - val_accuracy: 0.7780\n",
            "Epoch 686/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1824 - accuracy: 0.9487 - val_loss: 0.7345 - val_accuracy: 0.8024\n",
            "Epoch 687/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1655 - accuracy: 0.9432 - val_loss: 0.9161 - val_accuracy: 0.7683\n",
            "Epoch 688/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1726 - accuracy: 0.9481 - val_loss: 0.8539 - val_accuracy: 0.7805\n",
            "Epoch 689/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1620 - accuracy: 0.9493 - val_loss: 0.9026 - val_accuracy: 0.7780\n",
            "Epoch 690/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1673 - accuracy: 0.9457 - val_loss: 0.9133 - val_accuracy: 0.7707\n",
            "Epoch 691/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1828 - accuracy: 0.9505 - val_loss: 0.8784 - val_accuracy: 0.7512\n",
            "Epoch 692/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1621 - accuracy: 0.9524 - val_loss: 0.8364 - val_accuracy: 0.7610\n",
            "Epoch 693/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1692 - accuracy: 0.9499 - val_loss: 0.7791 - val_accuracy: 0.7927\n",
            "Epoch 694/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2178 - accuracy: 0.9389 - val_loss: 0.7580 - val_accuracy: 0.7976\n",
            "Epoch 695/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1685 - accuracy: 0.9567 - val_loss: 0.8024 - val_accuracy: 0.7585\n",
            "Epoch 696/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1585 - accuracy: 0.9469 - val_loss: 0.8059 - val_accuracy: 0.7683\n",
            "Epoch 697/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1918 - accuracy: 0.9402 - val_loss: 0.8331 - val_accuracy: 0.7732\n",
            "Epoch 698/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1623 - accuracy: 0.9512 - val_loss: 0.8592 - val_accuracy: 0.7634\n",
            "Epoch 699/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1715 - accuracy: 0.9518 - val_loss: 0.8219 - val_accuracy: 0.7927\n",
            "Epoch 700/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2006 - accuracy: 0.9444 - val_loss: 0.8000 - val_accuracy: 0.7976\n",
            "Epoch 701/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1917 - accuracy: 0.9457 - val_loss: 0.7383 - val_accuracy: 0.8049\n",
            "Epoch 702/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2432 - accuracy: 0.9310 - val_loss: 0.7551 - val_accuracy: 0.8146\n",
            "Epoch 703/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1867 - accuracy: 0.9481 - val_loss: 0.7511 - val_accuracy: 0.8024\n",
            "Epoch 704/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1381 - accuracy: 0.9554 - val_loss: 0.9436 - val_accuracy: 0.7585\n",
            "Epoch 705/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1417 - accuracy: 0.9567 - val_loss: 0.7723 - val_accuracy: 0.8098\n",
            "Epoch 706/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1939 - accuracy: 0.9469 - val_loss: 0.8676 - val_accuracy: 0.7780\n",
            "Epoch 707/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1749 - accuracy: 0.9469 - val_loss: 0.9040 - val_accuracy: 0.7732\n",
            "Epoch 708/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1582 - accuracy: 0.9518 - val_loss: 0.8864 - val_accuracy: 0.7902\n",
            "Epoch 709/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1722 - accuracy: 0.9438 - val_loss: 0.9139 - val_accuracy: 0.7780\n",
            "Epoch 710/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2283 - accuracy: 0.9426 - val_loss: 0.7540 - val_accuracy: 0.7927\n",
            "Epoch 711/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1600 - accuracy: 0.9536 - val_loss: 0.8291 - val_accuracy: 0.7902\n",
            "Epoch 712/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1846 - accuracy: 0.9487 - val_loss: 1.0021 - val_accuracy: 0.7317\n",
            "Epoch 713/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1853 - accuracy: 0.9457 - val_loss: 0.9707 - val_accuracy: 0.7610\n",
            "Epoch 714/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1539 - accuracy: 0.9603 - val_loss: 0.8511 - val_accuracy: 0.7927\n",
            "Epoch 715/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1695 - accuracy: 0.9481 - val_loss: 0.8576 - val_accuracy: 0.7902\n",
            "Epoch 716/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1491 - accuracy: 0.9554 - val_loss: 0.9098 - val_accuracy: 0.7878\n",
            "Epoch 717/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1753 - accuracy: 0.9420 - val_loss: 0.9067 - val_accuracy: 0.7805\n",
            "Epoch 718/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2216 - accuracy: 0.9408 - val_loss: 0.8136 - val_accuracy: 0.8220\n",
            "Epoch 719/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1895 - accuracy: 0.9457 - val_loss: 0.8101 - val_accuracy: 0.8098\n",
            "Epoch 720/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1503 - accuracy: 0.9524 - val_loss: 0.8293 - val_accuracy: 0.8049\n",
            "Epoch 721/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1519 - accuracy: 0.9499 - val_loss: 0.8079 - val_accuracy: 0.8073\n",
            "Epoch 722/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1496 - accuracy: 0.9579 - val_loss: 0.9560 - val_accuracy: 0.7756\n",
            "Epoch 723/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2250 - accuracy: 0.9383 - val_loss: 0.8025 - val_accuracy: 0.8122\n",
            "Epoch 724/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2065 - accuracy: 0.9493 - val_loss: 0.9204 - val_accuracy: 0.7512\n",
            "Epoch 725/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1825 - accuracy: 0.9432 - val_loss: 0.9237 - val_accuracy: 0.7756\n",
            "Epoch 726/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1750 - accuracy: 0.9463 - val_loss: 0.8545 - val_accuracy: 0.7829\n",
            "Epoch 727/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1546 - accuracy: 0.9524 - val_loss: 0.8719 - val_accuracy: 0.7732\n",
            "Epoch 728/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1809 - accuracy: 0.9481 - val_loss: 0.8522 - val_accuracy: 0.7927\n",
            "Epoch 729/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1648 - accuracy: 0.9505 - val_loss: 0.8178 - val_accuracy: 0.7878\n",
            "Epoch 730/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1635 - accuracy: 0.9493 - val_loss: 0.8797 - val_accuracy: 0.7780\n",
            "Epoch 731/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2028 - accuracy: 0.9438 - val_loss: 0.9661 - val_accuracy: 0.7707\n",
            "Epoch 732/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1960 - accuracy: 0.9438 - val_loss: 0.8253 - val_accuracy: 0.7927\n",
            "Epoch 733/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1612 - accuracy: 0.9530 - val_loss: 0.8141 - val_accuracy: 0.7780\n",
            "Epoch 734/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1679 - accuracy: 0.9524 - val_loss: 0.8158 - val_accuracy: 0.7902\n",
            "Epoch 735/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1473 - accuracy: 0.9518 - val_loss: 0.8117 - val_accuracy: 0.7829\n",
            "Epoch 736/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1742 - accuracy: 0.9487 - val_loss: 0.8784 - val_accuracy: 0.7927\n",
            "Epoch 737/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2050 - accuracy: 0.9438 - val_loss: 1.2261 - val_accuracy: 0.7098\n",
            "Epoch 738/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2622 - accuracy: 0.9304 - val_loss: 0.8666 - val_accuracy: 0.7878\n",
            "Epoch 739/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1718 - accuracy: 0.9451 - val_loss: 0.9055 - val_accuracy: 0.7756\n",
            "Epoch 740/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1643 - accuracy: 0.9512 - val_loss: 0.8337 - val_accuracy: 0.8024\n",
            "Epoch 741/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1888 - accuracy: 0.9438 - val_loss: 1.0461 - val_accuracy: 0.7390\n",
            "Epoch 742/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1584 - accuracy: 0.9530 - val_loss: 0.8869 - val_accuracy: 0.7902\n",
            "Epoch 743/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1709 - accuracy: 0.9451 - val_loss: 0.9227 - val_accuracy: 0.7829\n",
            "Epoch 744/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1479 - accuracy: 0.9567 - val_loss: 0.8979 - val_accuracy: 0.7707\n",
            "Epoch 745/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1427 - accuracy: 0.9603 - val_loss: 0.9611 - val_accuracy: 0.7902\n",
            "Epoch 746/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1928 - accuracy: 0.9512 - val_loss: 0.9882 - val_accuracy: 0.7732\n",
            "Epoch 747/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1815 - accuracy: 0.9524 - val_loss: 0.9768 - val_accuracy: 0.7732\n",
            "Epoch 748/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1744 - accuracy: 0.9463 - val_loss: 0.8667 - val_accuracy: 0.7805\n",
            "Epoch 749/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1845 - accuracy: 0.9481 - val_loss: 1.0368 - val_accuracy: 0.7488\n",
            "Epoch 750/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1747 - accuracy: 0.9463 - val_loss: 0.9974 - val_accuracy: 0.7659\n",
            "Epoch 751/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1328 - accuracy: 0.9621 - val_loss: 0.9776 - val_accuracy: 0.7829\n",
            "Epoch 752/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2223 - accuracy: 0.9463 - val_loss: 0.9295 - val_accuracy: 0.7707\n",
            "Epoch 753/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1451 - accuracy: 0.9554 - val_loss: 0.8562 - val_accuracy: 0.7683\n",
            "Epoch 754/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1523 - accuracy: 0.9499 - val_loss: 0.9132 - val_accuracy: 0.7829\n",
            "Epoch 755/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1559 - accuracy: 0.9560 - val_loss: 0.8606 - val_accuracy: 0.7854\n",
            "Epoch 756/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1355 - accuracy: 0.9597 - val_loss: 0.9064 - val_accuracy: 0.7707\n",
            "Epoch 757/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1542 - accuracy: 0.9505 - val_loss: 0.9341 - val_accuracy: 0.7659\n",
            "Epoch 758/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1524 - accuracy: 0.9542 - val_loss: 0.9159 - val_accuracy: 0.7683\n",
            "Epoch 759/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1969 - accuracy: 0.9396 - val_loss: 0.9082 - val_accuracy: 0.7756\n",
            "Epoch 760/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1738 - accuracy: 0.9481 - val_loss: 0.8109 - val_accuracy: 0.7878\n",
            "Epoch 761/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1674 - accuracy: 0.9487 - val_loss: 0.9156 - val_accuracy: 0.7561\n",
            "Epoch 762/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1768 - accuracy: 0.9481 - val_loss: 0.9424 - val_accuracy: 0.7390\n",
            "Epoch 763/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1254 - accuracy: 0.9597 - val_loss: 0.9321 - val_accuracy: 0.7537\n",
            "Epoch 764/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1135 - accuracy: 0.9676 - val_loss: 0.9435 - val_accuracy: 0.7634\n",
            "Epoch 765/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1876 - accuracy: 0.9505 - val_loss: 0.8483 - val_accuracy: 0.7756\n",
            "Epoch 766/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1898 - accuracy: 0.9432 - val_loss: 0.8639 - val_accuracy: 0.7805\n",
            "Epoch 767/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1499 - accuracy: 0.9505 - val_loss: 0.9592 - val_accuracy: 0.7488\n",
            "Epoch 768/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1710 - accuracy: 0.9524 - val_loss: 0.9181 - val_accuracy: 0.7683\n",
            "Epoch 769/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2031 - accuracy: 0.9426 - val_loss: 0.9431 - val_accuracy: 0.7537\n",
            "Epoch 770/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1532 - accuracy: 0.9567 - val_loss: 0.9300 - val_accuracy: 0.7634\n",
            "Epoch 771/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1536 - accuracy: 0.9567 - val_loss: 0.9392 - val_accuracy: 0.7634\n",
            "Epoch 772/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1825 - accuracy: 0.9493 - val_loss: 0.7983 - val_accuracy: 0.7976\n",
            "Epoch 773/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1791 - accuracy: 0.9426 - val_loss: 0.8770 - val_accuracy: 0.7659\n",
            "Epoch 774/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1716 - accuracy: 0.9499 - val_loss: 0.8674 - val_accuracy: 0.8024\n",
            "Epoch 775/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1446 - accuracy: 0.9579 - val_loss: 0.8724 - val_accuracy: 0.7878\n",
            "Epoch 776/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1741 - accuracy: 0.9548 - val_loss: 0.9461 - val_accuracy: 0.7732\n",
            "Epoch 777/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1869 - accuracy: 0.9560 - val_loss: 0.8266 - val_accuracy: 0.7854\n",
            "Epoch 778/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2073 - accuracy: 0.9451 - val_loss: 0.8544 - val_accuracy: 0.7707\n",
            "Epoch 779/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2121 - accuracy: 0.9463 - val_loss: 0.7479 - val_accuracy: 0.8073\n",
            "Epoch 780/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1877 - accuracy: 0.9457 - val_loss: 0.7775 - val_accuracy: 0.7854\n",
            "Epoch 781/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1966 - accuracy: 0.9389 - val_loss: 0.7637 - val_accuracy: 0.7927\n",
            "Epoch 782/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1853 - accuracy: 0.9493 - val_loss: 0.8955 - val_accuracy: 0.7683\n",
            "Epoch 783/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1832 - accuracy: 0.9457 - val_loss: 0.7979 - val_accuracy: 0.7927\n",
            "Epoch 784/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1595 - accuracy: 0.9505 - val_loss: 0.8718 - val_accuracy: 0.7878\n",
            "Epoch 785/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1450 - accuracy: 0.9475 - val_loss: 0.9905 - val_accuracy: 0.7732\n",
            "Epoch 786/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1585 - accuracy: 0.9548 - val_loss: 0.9611 - val_accuracy: 0.7659\n",
            "Epoch 787/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1583 - accuracy: 0.9536 - val_loss: 0.9020 - val_accuracy: 0.7780\n",
            "Epoch 788/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1650 - accuracy: 0.9512 - val_loss: 0.9107 - val_accuracy: 0.7854\n",
            "Epoch 789/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1794 - accuracy: 0.9524 - val_loss: 0.8457 - val_accuracy: 0.7756\n",
            "Epoch 790/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1624 - accuracy: 0.9487 - val_loss: 0.8292 - val_accuracy: 0.7902\n",
            "Epoch 791/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1565 - accuracy: 0.9548 - val_loss: 0.8429 - val_accuracy: 0.7976\n",
            "Epoch 792/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1271 - accuracy: 0.9634 - val_loss: 0.8589 - val_accuracy: 0.8049\n",
            "Epoch 793/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1698 - accuracy: 0.9554 - val_loss: 0.9216 - val_accuracy: 0.7854\n",
            "Epoch 794/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1819 - accuracy: 0.9548 - val_loss: 0.9919 - val_accuracy: 0.7732\n",
            "Epoch 795/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1914 - accuracy: 0.9359 - val_loss: 0.9124 - val_accuracy: 0.7707\n",
            "Epoch 796/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1898 - accuracy: 0.9512 - val_loss: 0.7786 - val_accuracy: 0.8000\n",
            "Epoch 797/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1504 - accuracy: 0.9579 - val_loss: 0.7635 - val_accuracy: 0.8073\n",
            "Epoch 798/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1656 - accuracy: 0.9463 - val_loss: 0.7958 - val_accuracy: 0.8073\n",
            "Epoch 799/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1936 - accuracy: 0.9536 - val_loss: 0.8293 - val_accuracy: 0.7805\n",
            "Epoch 800/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2171 - accuracy: 0.9444 - val_loss: 0.8046 - val_accuracy: 0.7976\n",
            "Epoch 801/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1748 - accuracy: 0.9505 - val_loss: 0.8850 - val_accuracy: 0.7683\n",
            "Epoch 802/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1355 - accuracy: 0.9554 - val_loss: 0.8606 - val_accuracy: 0.7854\n",
            "Epoch 803/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1499 - accuracy: 0.9548 - val_loss: 0.8324 - val_accuracy: 0.7976\n",
            "Epoch 804/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1601 - accuracy: 0.9469 - val_loss: 0.8530 - val_accuracy: 0.7927\n",
            "Epoch 805/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1905 - accuracy: 0.9524 - val_loss: 0.8907 - val_accuracy: 0.7732\n",
            "Epoch 806/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1768 - accuracy: 0.9505 - val_loss: 0.8527 - val_accuracy: 0.7780\n",
            "Epoch 807/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1588 - accuracy: 0.9585 - val_loss: 0.8181 - val_accuracy: 0.7878\n",
            "Epoch 808/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1681 - accuracy: 0.9475 - val_loss: 0.8464 - val_accuracy: 0.7829\n",
            "Epoch 809/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1682 - accuracy: 0.9554 - val_loss: 0.8676 - val_accuracy: 0.7805\n",
            "Epoch 810/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1465 - accuracy: 0.9524 - val_loss: 0.9926 - val_accuracy: 0.7732\n",
            "Epoch 811/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1673 - accuracy: 0.9585 - val_loss: 0.9136 - val_accuracy: 0.7854\n",
            "Epoch 812/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1780 - accuracy: 0.9481 - val_loss: 0.9689 - val_accuracy: 0.7585\n",
            "Epoch 813/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2071 - accuracy: 0.9505 - val_loss: 0.9605 - val_accuracy: 0.7512\n",
            "Epoch 814/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1895 - accuracy: 0.9499 - val_loss: 0.9850 - val_accuracy: 0.7585\n",
            "Epoch 815/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2109 - accuracy: 0.9389 - val_loss: 0.9590 - val_accuracy: 0.7683\n",
            "Epoch 816/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2106 - accuracy: 0.9402 - val_loss: 0.8777 - val_accuracy: 0.7683\n",
            "Epoch 817/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1861 - accuracy: 0.9451 - val_loss: 0.8720 - val_accuracy: 0.7805\n",
            "Epoch 818/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1723 - accuracy: 0.9505 - val_loss: 0.9182 - val_accuracy: 0.7829\n",
            "Epoch 819/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2176 - accuracy: 0.9444 - val_loss: 0.8362 - val_accuracy: 0.7732\n",
            "Epoch 820/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2251 - accuracy: 0.9341 - val_loss: 0.8518 - val_accuracy: 0.7780\n",
            "Epoch 821/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2072 - accuracy: 0.9316 - val_loss: 0.8242 - val_accuracy: 0.7829\n",
            "Epoch 822/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2018 - accuracy: 0.9438 - val_loss: 0.8492 - val_accuracy: 0.7707\n",
            "Epoch 823/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2388 - accuracy: 0.9365 - val_loss: 0.8507 - val_accuracy: 0.7805\n",
            "Epoch 824/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1960 - accuracy: 0.9481 - val_loss: 0.8112 - val_accuracy: 0.7829\n",
            "Epoch 825/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2384 - accuracy: 0.9383 - val_loss: 0.8060 - val_accuracy: 0.7756\n",
            "Epoch 826/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2149 - accuracy: 0.9347 - val_loss: 0.8824 - val_accuracy: 0.7683\n",
            "Epoch 827/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1848 - accuracy: 0.9505 - val_loss: 0.8517 - val_accuracy: 0.7805\n",
            "Epoch 828/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2237 - accuracy: 0.9371 - val_loss: 0.8372 - val_accuracy: 0.7854\n",
            "Epoch 829/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2131 - accuracy: 0.9402 - val_loss: 0.8640 - val_accuracy: 0.7829\n",
            "Epoch 830/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1620 - accuracy: 0.9487 - val_loss: 1.0335 - val_accuracy: 0.7463\n",
            "Epoch 831/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1761 - accuracy: 0.9487 - val_loss: 0.9273 - val_accuracy: 0.7780\n",
            "Epoch 832/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2038 - accuracy: 0.9481 - val_loss: 0.9801 - val_accuracy: 0.7659\n",
            "Epoch 833/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2372 - accuracy: 0.9280 - val_loss: 0.8659 - val_accuracy: 0.7756\n",
            "Epoch 834/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2294 - accuracy: 0.9341 - val_loss: 0.8887 - val_accuracy: 0.7756\n",
            "Epoch 835/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1270 - accuracy: 0.9591 - val_loss: 0.9690 - val_accuracy: 0.7610\n",
            "Epoch 836/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1342 - accuracy: 0.9664 - val_loss: 0.9198 - val_accuracy: 0.7732\n",
            "Epoch 837/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1332 - accuracy: 0.9579 - val_loss: 0.9120 - val_accuracy: 0.7756\n",
            "Epoch 838/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1757 - accuracy: 0.9493 - val_loss: 0.9317 - val_accuracy: 0.7756\n",
            "Epoch 839/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1744 - accuracy: 0.9530 - val_loss: 0.9547 - val_accuracy: 0.7707\n",
            "Epoch 840/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1540 - accuracy: 0.9567 - val_loss: 0.8829 - val_accuracy: 0.7976\n",
            "Epoch 841/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1266 - accuracy: 0.9621 - val_loss: 0.9650 - val_accuracy: 0.7707\n",
            "Epoch 842/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1295 - accuracy: 0.9646 - val_loss: 0.9094 - val_accuracy: 0.7902\n",
            "Epoch 843/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2072 - accuracy: 0.9493 - val_loss: 1.0075 - val_accuracy: 0.7610\n",
            "Epoch 844/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1655 - accuracy: 0.9481 - val_loss: 0.8535 - val_accuracy: 0.8000\n",
            "Epoch 845/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1887 - accuracy: 0.9493 - val_loss: 0.9276 - val_accuracy: 0.7878\n",
            "Epoch 846/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1333 - accuracy: 0.9597 - val_loss: 0.8810 - val_accuracy: 0.7829\n",
            "Epoch 847/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1542 - accuracy: 0.9542 - val_loss: 0.9037 - val_accuracy: 0.7805\n",
            "Epoch 848/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1406 - accuracy: 0.9554 - val_loss: 0.7932 - val_accuracy: 0.7927\n",
            "Epoch 849/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1557 - accuracy: 0.9524 - val_loss: 0.8368 - val_accuracy: 0.7732\n",
            "Epoch 850/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1912 - accuracy: 0.9475 - val_loss: 0.7965 - val_accuracy: 0.7951\n",
            "Epoch 851/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1362 - accuracy: 0.9548 - val_loss: 0.7822 - val_accuracy: 0.7976\n",
            "Epoch 852/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1629 - accuracy: 0.9524 - val_loss: 0.7760 - val_accuracy: 0.8122\n",
            "Epoch 853/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1545 - accuracy: 0.9585 - val_loss: 0.8942 - val_accuracy: 0.7683\n",
            "Epoch 854/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1915 - accuracy: 0.9475 - val_loss: 0.9520 - val_accuracy: 0.7537\n",
            "Epoch 855/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1728 - accuracy: 0.9548 - val_loss: 0.9210 - val_accuracy: 0.7634\n",
            "Epoch 856/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2003 - accuracy: 0.9438 - val_loss: 0.8176 - val_accuracy: 0.7707\n",
            "Epoch 857/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1391 - accuracy: 0.9567 - val_loss: 0.8674 - val_accuracy: 0.7756\n",
            "Epoch 858/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1522 - accuracy: 0.9567 - val_loss: 0.8436 - val_accuracy: 0.7829\n",
            "Epoch 859/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2084 - accuracy: 0.9438 - val_loss: 0.8393 - val_accuracy: 0.7732\n",
            "Epoch 860/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1738 - accuracy: 0.9463 - val_loss: 0.8820 - val_accuracy: 0.7683\n",
            "Epoch 861/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2030 - accuracy: 0.9438 - val_loss: 0.8574 - val_accuracy: 0.7854\n",
            "Epoch 862/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1931 - accuracy: 0.9438 - val_loss: 0.9362 - val_accuracy: 0.7805\n",
            "Epoch 863/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2508 - accuracy: 0.9249 - val_loss: 0.9020 - val_accuracy: 0.7756\n",
            "Epoch 864/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2527 - accuracy: 0.9316 - val_loss: 0.8649 - val_accuracy: 0.7683\n",
            "Epoch 865/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2388 - accuracy: 0.9316 - val_loss: 0.9740 - val_accuracy: 0.7390\n",
            "Epoch 866/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1732 - accuracy: 0.9457 - val_loss: 0.8917 - val_accuracy: 0.7732\n",
            "Epoch 867/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2095 - accuracy: 0.9402 - val_loss: 0.8874 - val_accuracy: 0.7537\n",
            "Epoch 868/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2040 - accuracy: 0.9451 - val_loss: 0.8918 - val_accuracy: 0.7463\n",
            "Epoch 869/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2525 - accuracy: 0.9274 - val_loss: 0.8230 - val_accuracy: 0.7683\n",
            "Epoch 870/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2015 - accuracy: 0.9481 - val_loss: 0.7865 - val_accuracy: 0.7829\n",
            "Epoch 871/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1557 - accuracy: 0.9487 - val_loss: 0.7716 - val_accuracy: 0.7854\n",
            "Epoch 872/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1659 - accuracy: 0.9451 - val_loss: 0.9097 - val_accuracy: 0.7683\n",
            "Epoch 873/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1800 - accuracy: 0.9512 - val_loss: 0.9778 - val_accuracy: 0.7415\n",
            "Epoch 874/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1720 - accuracy: 0.9475 - val_loss: 0.9552 - val_accuracy: 0.7585\n",
            "Epoch 875/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1827 - accuracy: 0.9530 - val_loss: 0.8910 - val_accuracy: 0.7707\n",
            "Epoch 876/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2158 - accuracy: 0.9347 - val_loss: 0.9157 - val_accuracy: 0.7634\n",
            "Epoch 877/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1782 - accuracy: 0.9444 - val_loss: 0.8787 - val_accuracy: 0.7902\n",
            "Epoch 878/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1868 - accuracy: 0.9530 - val_loss: 0.9484 - val_accuracy: 0.7707\n",
            "Epoch 879/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1953 - accuracy: 0.9463 - val_loss: 0.8439 - val_accuracy: 0.7976\n",
            "Epoch 880/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1590 - accuracy: 0.9567 - val_loss: 0.7916 - val_accuracy: 0.7951\n",
            "Epoch 881/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1854 - accuracy: 0.9469 - val_loss: 0.8283 - val_accuracy: 0.7976\n",
            "Epoch 882/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1869 - accuracy: 0.9451 - val_loss: 0.8615 - val_accuracy: 0.7634\n",
            "Epoch 883/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1903 - accuracy: 0.9536 - val_loss: 0.9031 - val_accuracy: 0.7683\n",
            "Epoch 884/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1471 - accuracy: 0.9518 - val_loss: 0.8292 - val_accuracy: 0.7829\n",
            "Epoch 885/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1666 - accuracy: 0.9524 - val_loss: 0.8558 - val_accuracy: 0.7829\n",
            "Epoch 886/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1589 - accuracy: 0.9609 - val_loss: 0.9645 - val_accuracy: 0.7561\n",
            "Epoch 887/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1852 - accuracy: 0.9420 - val_loss: 0.9208 - val_accuracy: 0.7732\n",
            "Epoch 888/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1836 - accuracy: 0.9505 - val_loss: 0.8560 - val_accuracy: 0.7634\n",
            "Epoch 889/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1979 - accuracy: 0.9432 - val_loss: 0.8433 - val_accuracy: 0.8073\n",
            "Epoch 890/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1887 - accuracy: 0.9493 - val_loss: 0.8560 - val_accuracy: 0.7854\n",
            "Epoch 891/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1835 - accuracy: 0.9475 - val_loss: 0.8738 - val_accuracy: 0.7854\n",
            "Epoch 892/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2188 - accuracy: 0.9383 - val_loss: 0.8998 - val_accuracy: 0.7707\n",
            "Epoch 893/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1935 - accuracy: 0.9463 - val_loss: 0.8683 - val_accuracy: 0.7829\n",
            "Epoch 894/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1428 - accuracy: 0.9567 - val_loss: 0.8324 - val_accuracy: 0.7805\n",
            "Epoch 895/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1321 - accuracy: 0.9621 - val_loss: 0.9645 - val_accuracy: 0.7610\n",
            "Epoch 896/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1456 - accuracy: 0.9615 - val_loss: 1.1097 - val_accuracy: 0.7268\n",
            "Epoch 897/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1778 - accuracy: 0.9451 - val_loss: 0.8619 - val_accuracy: 0.7927\n",
            "Epoch 898/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1759 - accuracy: 0.9451 - val_loss: 0.8983 - val_accuracy: 0.8049\n",
            "Epoch 899/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1598 - accuracy: 0.9505 - val_loss: 0.9922 - val_accuracy: 0.7683\n",
            "Epoch 900/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1398 - accuracy: 0.9609 - val_loss: 0.8812 - val_accuracy: 0.8000\n",
            "Epoch 901/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1873 - accuracy: 0.9505 - val_loss: 0.8952 - val_accuracy: 0.7829\n",
            "Epoch 902/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1827 - accuracy: 0.9444 - val_loss: 0.9256 - val_accuracy: 0.7610\n",
            "Epoch 903/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2181 - accuracy: 0.9396 - val_loss: 0.8833 - val_accuracy: 0.7732\n",
            "Epoch 904/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1638 - accuracy: 0.9536 - val_loss: 0.8727 - val_accuracy: 0.7659\n",
            "Epoch 905/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1962 - accuracy: 0.9518 - val_loss: 0.8207 - val_accuracy: 0.7780\n",
            "Epoch 906/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1428 - accuracy: 0.9554 - val_loss: 0.8034 - val_accuracy: 0.7951\n",
            "Epoch 907/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1816 - accuracy: 0.9451 - val_loss: 0.9086 - val_accuracy: 0.7707\n",
            "Epoch 908/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1681 - accuracy: 0.9536 - val_loss: 0.7987 - val_accuracy: 0.8049\n",
            "Epoch 909/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1958 - accuracy: 0.9469 - val_loss: 1.0197 - val_accuracy: 0.7488\n",
            "Epoch 910/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1549 - accuracy: 0.9585 - val_loss: 0.8998 - val_accuracy: 0.7756\n",
            "Epoch 911/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1736 - accuracy: 0.9438 - val_loss: 1.0118 - val_accuracy: 0.7341\n",
            "Epoch 912/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1891 - accuracy: 0.9518 - val_loss: 0.9091 - val_accuracy: 0.7610\n",
            "Epoch 913/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1893 - accuracy: 0.9463 - val_loss: 0.8877 - val_accuracy: 0.7829\n",
            "Epoch 914/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1843 - accuracy: 0.9408 - val_loss: 1.0204 - val_accuracy: 0.7512\n",
            "Epoch 915/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1666 - accuracy: 0.9457 - val_loss: 0.9155 - val_accuracy: 0.7805\n",
            "Epoch 916/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1426 - accuracy: 0.9512 - val_loss: 0.9714 - val_accuracy: 0.7878\n",
            "Epoch 917/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2243 - accuracy: 0.9475 - val_loss: 0.9340 - val_accuracy: 0.7659\n",
            "Epoch 918/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1897 - accuracy: 0.9512 - val_loss: 0.9523 - val_accuracy: 0.7415\n",
            "Epoch 919/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1939 - accuracy: 0.9505 - val_loss: 0.9041 - val_accuracy: 0.7732\n",
            "Epoch 920/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2138 - accuracy: 0.9377 - val_loss: 0.9745 - val_accuracy: 0.7585\n",
            "Epoch 921/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1814 - accuracy: 0.9554 - val_loss: 1.0878 - val_accuracy: 0.7439\n",
            "Epoch 922/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1755 - accuracy: 0.9451 - val_loss: 0.8561 - val_accuracy: 0.7927\n",
            "Epoch 923/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1653 - accuracy: 0.9542 - val_loss: 0.9617 - val_accuracy: 0.7512\n",
            "Epoch 924/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1508 - accuracy: 0.9573 - val_loss: 0.9909 - val_accuracy: 0.7780\n",
            "Epoch 925/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1571 - accuracy: 0.9560 - val_loss: 0.9990 - val_accuracy: 0.7683\n",
            "Epoch 926/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1766 - accuracy: 0.9518 - val_loss: 1.1427 - val_accuracy: 0.7463\n",
            "Epoch 927/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1577 - accuracy: 0.9536 - val_loss: 1.0339 - val_accuracy: 0.7707\n",
            "Epoch 928/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2057 - accuracy: 0.9438 - val_loss: 1.0255 - val_accuracy: 0.7585\n",
            "Epoch 929/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2254 - accuracy: 0.9438 - val_loss: 0.9587 - val_accuracy: 0.7683\n",
            "Epoch 930/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2110 - accuracy: 0.9414 - val_loss: 0.9872 - val_accuracy: 0.7610\n",
            "Epoch 931/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.2053 - accuracy: 0.9414 - val_loss: 0.8592 - val_accuracy: 0.7854\n",
            "Epoch 932/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1707 - accuracy: 0.9469 - val_loss: 0.9409 - val_accuracy: 0.7707\n",
            "Epoch 933/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1673 - accuracy: 0.9481 - val_loss: 1.0284 - val_accuracy: 0.7488\n",
            "Epoch 934/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1922 - accuracy: 0.9487 - val_loss: 0.8692 - val_accuracy: 0.7756\n",
            "Epoch 935/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1673 - accuracy: 0.9493 - val_loss: 0.9366 - val_accuracy: 0.7561\n",
            "Epoch 936/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1173 - accuracy: 0.9603 - val_loss: 0.9578 - val_accuracy: 0.7878\n",
            "Epoch 937/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1544 - accuracy: 0.9548 - val_loss: 1.0466 - val_accuracy: 0.7561\n",
            "Epoch 938/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1128 - accuracy: 0.9646 - val_loss: 1.0256 - val_accuracy: 0.7610\n",
            "Epoch 939/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1675 - accuracy: 0.9634 - val_loss: 1.0314 - val_accuracy: 0.7585\n",
            "Epoch 940/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1659 - accuracy: 0.9499 - val_loss: 0.9743 - val_accuracy: 0.7683\n",
            "Epoch 941/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1916 - accuracy: 0.9499 - val_loss: 0.9907 - val_accuracy: 0.7732\n",
            "Epoch 942/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1597 - accuracy: 0.9548 - val_loss: 0.8985 - val_accuracy: 0.7805\n",
            "Epoch 943/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1666 - accuracy: 0.9542 - val_loss: 0.9887 - val_accuracy: 0.7610\n",
            "Epoch 944/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1380 - accuracy: 0.9512 - val_loss: 0.9714 - val_accuracy: 0.7683\n",
            "Epoch 945/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1647 - accuracy: 0.9560 - val_loss: 1.0067 - val_accuracy: 0.7683\n",
            "Epoch 946/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1910 - accuracy: 0.9530 - val_loss: 0.9835 - val_accuracy: 0.7805\n",
            "Epoch 947/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1502 - accuracy: 0.9579 - val_loss: 0.8789 - val_accuracy: 0.7854\n",
            "Epoch 948/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1286 - accuracy: 0.9597 - val_loss: 0.9337 - val_accuracy: 0.7756\n",
            "Epoch 949/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1659 - accuracy: 0.9469 - val_loss: 0.9583 - val_accuracy: 0.7561\n",
            "Epoch 950/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1232 - accuracy: 0.9640 - val_loss: 0.9291 - val_accuracy: 0.7683\n",
            "Epoch 951/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1926 - accuracy: 0.9475 - val_loss: 1.1122 - val_accuracy: 0.7341\n",
            "Epoch 952/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1849 - accuracy: 0.9457 - val_loss: 0.9163 - val_accuracy: 0.7732\n",
            "Epoch 953/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1333 - accuracy: 0.9542 - val_loss: 0.9612 - val_accuracy: 0.7512\n",
            "Epoch 954/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1551 - accuracy: 0.9591 - val_loss: 0.9425 - val_accuracy: 0.7634\n",
            "Epoch 955/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1612 - accuracy: 0.9567 - val_loss: 0.8947 - val_accuracy: 0.7902\n",
            "Epoch 956/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1636 - accuracy: 0.9499 - val_loss: 1.0250 - val_accuracy: 0.7537\n",
            "Epoch 957/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1600 - accuracy: 0.9536 - val_loss: 0.9989 - val_accuracy: 0.7610\n",
            "Epoch 958/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1561 - accuracy: 0.9554 - val_loss: 1.0102 - val_accuracy: 0.7707\n",
            "Epoch 959/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1872 - accuracy: 0.9475 - val_loss: 0.9115 - val_accuracy: 0.8098\n",
            "Epoch 960/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1622 - accuracy: 0.9499 - val_loss: 0.9507 - val_accuracy: 0.7878\n",
            "Epoch 961/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1935 - accuracy: 0.9518 - val_loss: 0.9688 - val_accuracy: 0.7683\n",
            "Epoch 962/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1748 - accuracy: 0.9493 - val_loss: 0.9458 - val_accuracy: 0.7756\n",
            "Epoch 963/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1606 - accuracy: 0.9591 - val_loss: 0.9991 - val_accuracy: 0.7634\n",
            "Epoch 964/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1416 - accuracy: 0.9579 - val_loss: 0.9267 - val_accuracy: 0.7805\n",
            "Epoch 965/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1587 - accuracy: 0.9585 - val_loss: 0.9974 - val_accuracy: 0.7634\n",
            "Epoch 966/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1459 - accuracy: 0.9536 - val_loss: 0.9311 - val_accuracy: 0.7707\n",
            "Epoch 967/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1664 - accuracy: 0.9573 - val_loss: 0.8879 - val_accuracy: 0.7780\n",
            "Epoch 968/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2070 - accuracy: 0.9414 - val_loss: 0.9116 - val_accuracy: 0.7780\n",
            "Epoch 969/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1501 - accuracy: 0.9585 - val_loss: 0.8543 - val_accuracy: 0.7756\n",
            "Epoch 970/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1690 - accuracy: 0.9469 - val_loss: 0.9098 - val_accuracy: 0.7683\n",
            "Epoch 971/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1670 - accuracy: 0.9548 - val_loss: 0.9614 - val_accuracy: 0.7634\n",
            "Epoch 972/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1305 - accuracy: 0.9597 - val_loss: 0.9110 - val_accuracy: 0.7707\n",
            "Epoch 973/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1964 - accuracy: 0.9463 - val_loss: 0.9093 - val_accuracy: 0.7561\n",
            "Epoch 974/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1580 - accuracy: 0.9505 - val_loss: 0.9231 - val_accuracy: 0.7610\n",
            "Epoch 975/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2038 - accuracy: 0.9499 - val_loss: 0.9503 - val_accuracy: 0.7659\n",
            "Epoch 976/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1572 - accuracy: 0.9499 - val_loss: 0.9623 - val_accuracy: 0.7732\n",
            "Epoch 977/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1241 - accuracy: 0.9609 - val_loss: 0.9426 - val_accuracy: 0.7951\n",
            "Epoch 978/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1558 - accuracy: 0.9640 - val_loss: 1.0412 - val_accuracy: 0.7780\n",
            "Epoch 979/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1543 - accuracy: 0.9554 - val_loss: 1.0547 - val_accuracy: 0.7512\n",
            "Epoch 980/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1630 - accuracy: 0.9579 - val_loss: 1.0278 - val_accuracy: 0.7805\n",
            "Epoch 981/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1463 - accuracy: 0.9609 - val_loss: 1.0015 - val_accuracy: 0.7854\n",
            "Epoch 982/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1365 - accuracy: 0.9615 - val_loss: 0.9184 - val_accuracy: 0.7976\n",
            "Epoch 983/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1617 - accuracy: 0.9560 - val_loss: 1.0854 - val_accuracy: 0.7634\n",
            "Epoch 984/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1673 - accuracy: 0.9487 - val_loss: 0.9639 - val_accuracy: 0.7659\n",
            "Epoch 985/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1669 - accuracy: 0.9536 - val_loss: 0.9859 - val_accuracy: 0.7732\n",
            "Epoch 986/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1767 - accuracy: 0.9475 - val_loss: 1.0607 - val_accuracy: 0.7463\n",
            "Epoch 987/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1465 - accuracy: 0.9579 - val_loss: 0.9620 - val_accuracy: 0.7829\n",
            "Epoch 988/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1970 - accuracy: 0.9518 - val_loss: 0.9325 - val_accuracy: 0.7976\n",
            "Epoch 989/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1784 - accuracy: 0.9457 - val_loss: 0.9491 - val_accuracy: 0.7805\n",
            "Epoch 990/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1868 - accuracy: 0.9475 - val_loss: 1.0452 - val_accuracy: 0.7561\n",
            "Epoch 991/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9573 - val_loss: 0.9315 - val_accuracy: 0.7829\n",
            "Epoch 992/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1720 - accuracy: 0.9542 - val_loss: 1.0526 - val_accuracy: 0.7659\n",
            "Epoch 993/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1659 - accuracy: 0.9475 - val_loss: 1.0266 - val_accuracy: 0.7634\n",
            "Epoch 994/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1522 - accuracy: 0.9585 - val_loss: 0.8981 - val_accuracy: 0.8049\n",
            "Epoch 995/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1517 - accuracy: 0.9524 - val_loss: 0.9765 - val_accuracy: 0.7878\n",
            "Epoch 996/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1577 - accuracy: 0.9530 - val_loss: 0.9238 - val_accuracy: 0.7805\n",
            "Epoch 997/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1495 - accuracy: 0.9591 - val_loss: 1.0006 - val_accuracy: 0.7854\n",
            "Epoch 998/1000\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.1708 - accuracy: 0.9524 - val_loss: 0.9999 - val_accuracy: 0.7780\n",
            "Epoch 999/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1421 - accuracy: 0.9585 - val_loss: 0.8957 - val_accuracy: 0.7805\n",
            "Epoch 1000/1000\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.1636 - accuracy: 0.9530 - val_loss: 0.9824 - val_accuracy: 0.7854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUBl2JX8vKKz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "outputId": "b16dcbcf-e704-41f0-9a7c-cb516f0040a9"
      },
      "source": [
        "\n",
        "print(\n",
        "    f\"resNET CNN : Epochs={EPOCHS:d}, \" +\n",
        "    f\"Train accuracy={max(hits.history['accuracy']):.4f}, \" +\n",
        "    f\"Validation accuracy={max(hits.history['val_accuracy']):.4f}\"\n",
        ")\n",
        "\n",
        "#예측모델 체크\n",
        "\n",
        "acc = hits.history['accuracy']\n",
        "val_acc = hits.history['val_accuracy']\n",
        "\n",
        "plt.plot(acc)\n",
        "plt.plot(val_acc)\n",
        "plt.title('Accuracy')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "loss = hits.history['loss']\n",
        "val_loss = hits.history['val_loss']\n",
        "\n",
        "plt.plot(loss)\n",
        "plt.plot(val_loss)\n",
        "plt.title('Loss')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "resNET CNN : Epochs=1000, Train accuracy=0.9676, Validation accuracy=0.8220\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugAuk0Pk2aF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#예측하기\n",
        "test_df = pd.read_csv('test.csv', index_col=0)\n",
        "x_predict = np.array(test_df.iloc[:, 1:]).reshape(-1, 28, 28, 1).astype(np.float)\n",
        "results = np.argmax(model.predict(x_predict), axis=1)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHdwGfOO4ZqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#제출\n",
        "submission_df = pd.read_csv('submission.csv', index_col=0)\n",
        "submission_df.digit = results\n",
        "submission_df.to_csv('result.csv')"
      ],
      "execution_count": 52,
      "outputs": []
    }
  ]
}